{"cells":[{"cell_type":"markdown","metadata":{"id":"-cf5-oDPjwf8"},"source":["# Unit 8: Proximal Policy Gradient (PPO) with PyTorch ü§ñ\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/thumbnail.png\" alt=\"Unit 8\"/>\n","\n","\n","In this notebook, you'll learn to **code your PPO agent from scratch with PyTorch using CleanRL implementation as model**.\n","\n","To test its robustness, we're going to train it in:\n","\n","- [LunarLander-v2 üöÄ](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)\n"]},{"cell_type":"markdown","metadata":{"id":"2Fl6Rxt0lc0O"},"source":["‚¨áÔ∏è Here is an example of what you will achieve. ‚¨áÔ∏è"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbKfCj5ilgqT"},"outputs":[],"source":["%%html\n","<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"]},{"cell_type":"markdown","metadata":{"id":"YcOFdWpnlxNf"},"source":["We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the GitHub Repo](https://github.com/huggingface/deep-rl-class/issues)."]},{"cell_type":"markdown","source":["## Objectives of this notebook üèÜ\n","\n","At the end of the notebook, you will:\n","\n","- Be able to **code your PPO agent from scratch using PyTorch**.\n","- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n","\n","\n"],"metadata":{"id":"T6lIPYFghhYL"}},{"cell_type":"markdown","source":["## This notebook is from the Deep Reinforcement Learning Course\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>\n","\n","In this free course, you will:\n","\n","- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n","- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n","- ü§ñ Train **agents in unique environments** \n","\n","Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n","\n","\n","The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"],"metadata":{"id":"Wp-rD6Fuhq31"}},{"cell_type":"markdown","source":["## Prerequisites üèóÔ∏è\n","Before diving into the notebook, you need to:\n","\n","üî≤ üìö Study [PPO by reading Unit 8](https://huggingface.co/deep-rl-course/unit8/introduction) ü§ó  "],"metadata":{"id":"rasqqGQlhujA"}},{"cell_type":"markdown","source":["To validate this hands-on for the [certification process](https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process), you need to push one model, we don't ask for a minimal result but we **advise you to try different hyperparameters settings to get better results**.\n","\n","If you don't find your model, **go to the bottom of the page and click on the refresh button**\n","\n","For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"],"metadata":{"id":"PUFfMGOih3CW"}},{"cell_type":"markdown","source":["## Set the GPU üí™\n","- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"],"metadata":{"id":"PU4FVzaoM6fC"}},{"cell_type":"markdown","source":["- `Hardware Accelerator > GPU`\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"],"metadata":{"id":"KV0NyFdQM9ZG"}},{"cell_type":"markdown","source":["## Create a virtual display üîΩ\n","\n","During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames). \n","\n","Hence the following cell will install the librairies and create and run a virtual screen üñ•"],"metadata":{"id":"bTpYcVZVMzUI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"jV6wjQ7Be7p5","executionInfo":{"status":"ok","timestamp":1679055260969,"user_tz":-60,"elapsed":26901,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"outputs":[],"source":["%%capture\n","!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","!pip install pyglet==1.5\n","!pip3 install pyvirtualdisplay"]},{"cell_type":"code","source":["# Virtual display\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()"],"metadata":{"id":"ww5PQH1gNLI4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679055261852,"user_tz":-60,"elapsed":887,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}},"outputId":"89112832-27fa-4fc8-bff6-bcfd15428330"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7f152ed6de80>"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"ncIgfNf3mOtc"},"source":["## Install dependencies üîΩ\n","For this exercise, we use `gym==0.21`\n"]},{"cell_type":"code","source":["!pip install gym==0.21\n","!pip install imageio-ffmpeg\n","!pip install huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrnG_NvTEbIv","executionInfo":{"status":"ok","timestamp":1679055284050,"user_tz":-60,"elapsed":22203,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}},"outputId":"f42f27f0-0b66-48c2-af08-1aac8589e7c8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gym==0.21\n","  Downloading gym-0.21.0.tar.gz (1.5 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.21) (1.22.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym==0.21) (2.2.1)\n","Building wheels for collected packages: gym\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for gym (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for gym\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for gym\n","Failed to build gym\n","Installing collected packages: gym\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","  Running setup.py install for gym ... \u001b[?25l\u001b[?25hdone\n","\u001b[33m  DEPRECATION: gym was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed gym-0.21.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imageio-ffmpeg\n","  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.4.8\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting huggingface_hub\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (2.25.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (6.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (3.9.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (1.26.15)\n","Installing collected packages: huggingface_hub\n","Successfully installed huggingface_hub-0.13.2\n"]}]},{"cell_type":"code","source":["%%capture\n","!apt-get install -y build-essential python-dev swig\n","!pip install box2d-py\n"],"metadata":{"id":"N-DtZsfCfTU_","executionInfo":{"status":"ok","timestamp":1679055411638,"user_tz":-60,"elapsed":60746,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#!pip install box2d\n","#!pip install gym[box2d]==0.21"],"metadata":{"id":"9xZQFTPcsKUK","executionInfo":{"status":"ok","timestamp":1679055411638,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oDkUufewmq6v"},"source":["## Let's code PPO from scratch with Costa Huang tutorial\n","- For the core implementation of PPO we're going to use the excellent [Costa Huang](https://costa.sh/) tutorial.\n","- In addition to the tutorial, to go deeper you can read the 37 core implementation details: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n","\n","üëâ The video tutorial: https://youtu.be/MEt6rrxH8W4"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"aNgEL1_uvhaq","colab":{"base_uri":"https://localhost:8080/","height":371},"executionInfo":{"status":"ok","timestamp":1679055431916,"user_tz":-60,"elapsed":243,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}},"outputId":"431278c2-b5a2-4acd-def8-ba8317aed458"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/display.py:701: UserWarning: Consider using IPython.display.IFrame instead\n","  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"]},"metadata":{},"execution_count":6}],"source":["from IPython.display import HTML\n","\n","HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"]},{"cell_type":"markdown","metadata":{"id":"f34ILn7AvTbt"},"source":["- The best is to code first on the cell below, this way, if you kill the machine **you don't loose the implementation**."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"_bE708C6mhE7","executionInfo":{"status":"ok","timestamp":1679050137133,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"outputs":[],"source":["### Your code here:"]},{"cell_type":"markdown","metadata":{"id":"mk-a9CmNuS2W"},"source":["## Add the Hugging Face Integration ü§ó\n","- In order to push our model to the Hub, we need to define a function `package_to_hub`"]},{"cell_type":"markdown","metadata":{"id":"TPi1Nme-oGWd"},"source":["- Add dependencies we need to push our model to the Hub"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Sj8bz-AmoNVj","executionInfo":{"status":"ok","timestamp":1679055564334,"user_tz":-60,"elapsed":238,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"outputs":[],"source":["from huggingface_hub import HfApi, upload_folder\n","from huggingface_hub.repocard import metadata_eval_result, metadata_save\n","\n","from pathlib import Path\n","import datetime\n","import tempfile\n","import json\n","import shutil\n","import imageio\n","\n","from wasabi import Printer\n","msg = Printer()"]},{"cell_type":"markdown","metadata":{"id":"5rDr8-lWn0zi"},"source":["- Add new argument in `parse_args()` function to define the repo-id where we want to push the model."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"iHQiqQEFn0QH","executionInfo":{"status":"ok","timestamp":1679055566303,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"outputs":[],"source":["# Adding HuggingFace argument\n","#parser.add_argument(\"--repo-id\", type=str, default=\"ahmad1289/ppo-CartPole-v1\", help=\"id of the model repository from the Hugging Face Hub {username/repo_name}\")"]},{"cell_type":"markdown","metadata":{"id":"blLZMiBAoUVT"},"source":["- Next, we add the methods needed to push the model to the Hub\n","\n","- These methods will:\n","  - `_evalutate_agent()`: evaluate the agent.\n","  - `_generate_model_card()`: generate the model card of your agent.\n","  - `_record_video()`: record a video of your agent."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WlLcz4L9odXs","executionInfo":{"status":"ok","timestamp":1679055571283,"user_tz":-60,"elapsed":335,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}}},"outputs":[],"source":["def package_to_hub(repo_id, \n","                model,\n","                hyperparameters,\n","                eval_env,\n","                video_fps=30,\n","                commit_message=\"Push agent to the Hub\",\n","                token= None,\n","                logs=None\n","                ):\n","  \"\"\"\n","  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n","  This method does the complete pipeline:\n","  - It evaluates the model\n","  - It generates the model card\n","  - It generates a replay video of the agent\n","  - It pushes everything to the hub\n","  :param repo_id: id of the model repository from the Hugging Face Hub\n","  :param model: trained model\n","  :param eval_env: environment used to evaluate the agent\n","  :param fps: number of fps for rendering the video\n","  :param commit_message: commit message\n","  :param logs: directory on local machine of tensorboard logs you'd like to upload\n","  \"\"\"\n","  msg.info(\n","        \"This function will save, evaluate, generate a video of your agent, \"\n","        \"create a model card and push everything to the hub. \"\n","        \"It might take up to 1min. \\n \"\n","        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n","    )\n","  # Step 1: Clone or create the repo\n","  repo_url = HfApi().create_repo(\n","        repo_id=repo_id,\n","        token=token,\n","        private=False,\n","        exist_ok=True,\n","    )\n","  \n","  with tempfile.TemporaryDirectory() as tmpdirname:\n","    tmpdirname = Path(tmpdirname)\n","\n","    # Step 2: Save the model\n","    torch.save(model.state_dict(), tmpdirname / \"model.pt\")\n","  \n","    # Step 3: Evaluate the model and build JSON\n","    mean_reward, std_reward = _evaluate_agent(eval_env, \n","                                           10, \n","                                           model)\n","\n","    # First get datetime\n","    eval_datetime = datetime.datetime.now()\n","    eval_form_datetime = eval_datetime.isoformat()\n","\n","    evaluate_data = {\n","        \"env_id\": hyperparameters.env_id, \n","        \"mean_reward\": mean_reward,\n","        \"std_reward\": std_reward,\n","        \"n_evaluation_episodes\": 10,\n","        \"eval_datetime\": eval_form_datetime,\n","    }\n"," \n","    # Write a JSON file\n","    with open(tmpdirname / \"results.json\", \"w\") as outfile:\n","      json.dump(evaluate_data, outfile)\n","\n","    # Step 4: Generate a video\n","    video_path =  tmpdirname / \"replay.mp4\"\n","    record_video(eval_env, model, video_path, video_fps)\n","  \n","    # Step 5: Generate the model card\n","    generated_model_card, metadata = _generate_model_card(\"PPO\", hyperparameters.env_id, mean_reward, std_reward, hyperparameters)\n","    _save_model_card(tmpdirname, generated_model_card, metadata)\n","\n","    # Step 6: Add logs if needed\n","    if logs:\n","      _add_logdir(tmpdirname, Path(logs))\n","  \n","    msg.info(f\"Pushing repo {repo_id} to the Hugging Face Hub\")\n","  \n","    repo_url = upload_folder(\n","            repo_id=repo_id,\n","            folder_path=tmpdirname,\n","            path_in_repo=\"\",\n","            commit_message=commit_message,\n","            token=token,\n","        )\n","\n","    msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n","  return repo_url\n","\n","\n","def _evaluate_agent(env, n_eval_episodes, policy):\n","  \"\"\"\n","  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n","  :param env: The evaluation environment\n","  :param n_eval_episodes: Number of episode to evaluate the agent\n","  :param policy: The agent\n","  \"\"\"\n","  episode_rewards = []\n","  for episode in range(n_eval_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards_ep = 0\n","    \n","    while done is False:\n","      state = torch.Tensor(state).to(device)\n","      action, _, _, _ = policy.get_action_and_value(state)\n","      new_state, reward, done, info = env.step(action.cpu().numpy())\n","      total_rewards_ep += reward    \n","      if done:\n","        break\n","      state = new_state\n","    episode_rewards.append(total_rewards_ep)\n","  mean_reward = np.mean(episode_rewards)\n","  std_reward = np.std(episode_rewards)\n","\n","  return mean_reward, std_reward\n","\n","\n","def record_video(env, policy, out_directory, fps=30):\n","  images = []  \n","  done = False\n","  state = env.reset()\n","  img = env.render(mode='rgb_array')\n","  images.append(img)\n","  while not done:\n","    state = torch.Tensor(state).to(device)\n","    # Take the action (index) that have the maximum expected future reward given that state\n","    action, _, _, _  = policy.get_action_and_value(state)\n","    state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n","    img = env.render(mode='rgb_array')\n","    images.append(img)\n","  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n","\n","\n","def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n","  \"\"\"\n","  Generate the model card for the Hub\n","  :param model_name: name of the model\n","  :env_id: name of the environment\n","  :mean_reward: mean reward of the agent\n","  :std_reward: standard deviation of the mean reward of the agent\n","  :hyperparameters: training arguments\n","  \"\"\"\n","  # Step 1: Select the tags\n","  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n","\n","  # Transform the hyperparams namespace to string\n","  converted_dict = vars(hyperparameters)\n","  converted_str = str(converted_dict)\n","  converted_str = converted_str.split(\", \")\n","  converted_str = '\\n'.join(converted_str)\n"," \n","  # Step 2: Generate the model card\n","  model_card = f\"\"\"\n","  # PPO Agent Playing {env_id}\n","\n","  This is a trained model of a PPO agent playing {env_id}.\n","    \n","  # Hyperparameters\n","  ```python\n","  {converted_str}\n","  ```\n","  \"\"\"\n","  return model_card, metadata\n","\n","\n","def generate_metadata(model_name, env_id, mean_reward, std_reward):\n","  \"\"\"\n","  Define the tags for the model card\n","  :param model_name: name of the model\n","  :param env_id: name of the environment\n","  :mean_reward: mean reward of the agent\n","  :std_reward: standard deviation of the mean reward of the agent\n","  \"\"\"\n","  metadata = {}\n","  metadata[\"tags\"] = [\n","        env_id,\n","        \"ppo\",\n","        \"deep-reinforcement-learning\",\n","        \"reinforcement-learning\",\n","        \"custom-implementation\",\n","        \"deep-rl-course\"\n","  ]\n","\n","  # Add metrics\n","  eval = metadata_eval_result(\n","      model_pretty_name=model_name,\n","      task_pretty_name=\"reinforcement-learning\",\n","      task_id=\"reinforcement-learning\",\n","      metrics_pretty_name=\"mean_reward\",\n","      metrics_id=\"mean_reward\",\n","      metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n","      dataset_pretty_name=env_id,\n","      dataset_id=env_id,\n","  )\n","\n","  # Merges both dictionaries\n","  metadata = {**metadata, **eval}\n","\n","  return metadata\n","\n","\n","def _save_model_card(local_path, generated_model_card, metadata):\n","    \"\"\"Saves a model card for the repository.\n","    :param local_path: repository directory\n","    :param generated_model_card: model card generated by _generate_model_card()\n","    :param metadata: metadata\n","    \"\"\"\n","    readme_path = local_path / \"README.md\"\n","    readme = \"\"\n","    if readme_path.exists():\n","        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n","            readme = f.read()\n","    else:\n","        readme = generated_model_card\n","\n","    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n","        f.write(readme)\n","\n","    # Save our metrics to Readme metadata\n","    metadata_save(readme_path, metadata)\n","\n","\n","def _add_logdir(local_path: Path, logdir: Path):\n","  \"\"\"Adds a logdir to the repository.\n","  :param local_path: repository directory\n","  :param logdir: logdir directory\n","  \"\"\"\n","  if logdir.exists() and logdir.is_dir():\n","    # Add the logdir to the repository under new dir called logs\n","    repo_logdir = local_path / \"logs\"\n","    \n","    # Delete current logs if they exist\n","    if repo_logdir.exists():\n","      shutil.rmtree(repo_logdir)\n","\n","    # Copy logdir into repo logdir\n","    shutil.copytree(logdir, repo_logdir)"]},{"cell_type":"markdown","metadata":{"id":"TqX8z8_rooD6"},"source":["- Finally, we call this function at the end of the PPO training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8V1vNiTo2hL"},"outputs":[],"source":["# Create the evaluation environment\n","eval_env = gym.make(args.env_id)\n","\n","package_to_hub(repo_id = args.repo_id,\n","                model = agent, # The model we want to save\n","                hyperparameters = args,\n","                eval_env = gym.make(args.env_id),\n","                logs= f\"runs/{run_name}\",\n","                )"]},{"cell_type":"markdown","metadata":{"id":"muCCzed4o5TC"},"source":["- Here's what look the ppo.py final file"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"LviRdtXgo7kF","colab":{"base_uri":"https://localhost:8080/","height":495},"executionInfo":{"status":"error","timestamp":1679046832930,"user_tz":-60,"elapsed":442,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}},"outputId":"b58a11f2-cfa8-414d-d4a1-2f03ffae851b"},"outputs":[{"output_type":"stream","name":"stderr","text":["usage: ipykernel_launcher.py [-h] [--exp-name EXP_NAME] [--seed SEED]\n","                             [--torch-deterministic [TORCH_DETERMINISTIC]]\n","                             [--cuda [CUDA]] [--track [TRACK]]\n","                             [--wandb-project-name WANDB_PROJECT_NAME]\n","                             [--wandb-entity WANDB_ENTITY]\n","                             [--capture-video [CAPTURE_VIDEO]]\n","                             [--env-id ENV_ID]\n","                             [--total-timesteps TOTAL_TIMESTEPS]\n","                             [--learning-rate LEARNING_RATE]\n","                             [--num-envs NUM_ENVS] [--num-steps NUM_STEPS]\n","                             [--anneal-lr [ANNEAL_LR]] [--gae [GAE]]\n","                             [--gamma GAMMA] [--gae-lambda GAE_LAMBDA]\n","                             [--num-minibatches NUM_MINIBATCHES]\n","                             [--update-epochs UPDATE_EPOCHS]\n","                             [--norm-adv [NORM_ADV]] [--clip-coef CLIP_COEF]\n","                             [--clip-vloss [CLIP_VLOSS]] [--ent-coef ENT_COEF]\n","                             [--vf-coef VF_COEF]\n","                             [--max-grad-norm MAX_GRAD_NORM]\n","                             [--target-kl TARGET_KL] [--repo-id REPO_ID]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-82b34c32-65a5-4710-81ed-5b5f366cf595.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}],"source":["# docs and experiment results can be found at https://docs.cleanrl.dev/rl-algorithms/ppo/#ppopy\n","\n","import argparse\n","import os\n","import random\n","import time\n","from distutils.util import strtobool\n","\n","import gym\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.distributions.categorical import Categorical\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from huggingface_hub import HfApi, upload_folder\n","from huggingface_hub.repocard import metadata_eval_result, metadata_save\n","\n","from pathlib import Path\n","import datetime\n","import tempfile\n","import json\n","import shutil\n","import imageio\n","\n","from wasabi import Printer\n","msg = Printer()\n","\n","def parse_args():\n","    # fmt: off\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--exp-name\", type=str, default=os.path.basename(__file__).rstrip(\".py\"),\n","        help=\"the name of this experiment\")\n","    parser.add_argument(\"--seed\", type=int, default=1,\n","        help=\"seed of the experiment\")\n","    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n","        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n","    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n","        help=\"if toggled, cuda will be enabled by default\")\n","    parser.add_argument(\"--track\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n","        help=\"if toggled, this experiment will be tracked with Weights and Biases\")\n","    parser.add_argument(\"--wandb-project-name\", type=str, default=\"cleanRL\",\n","        help=\"the wandb's project name\")\n","    parser.add_argument(\"--wandb-entity\", type=str, default=None,\n","        help=\"the entity (team) of wandb's project\")\n","    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=False, nargs=\"?\", const=True,\n","        help=\"weather to capture videos of the agent performances (check out `videos` folder)\")\n","\n","    # Algorithm specific arguments\n","    parser.add_argument(\"--env-id\", type=str, default=\"CartPole-v1\",\n","        help=\"the id of the environment\")\n","    parser.add_argument(\"--total-timesteps\", type=int, default=50000,\n","        help=\"total timesteps of the experiments\")\n","    parser.add_argument(\"--learning-rate\", type=float, default=2.5e-4,\n","        help=\"the learning rate of the optimizer\")\n","    parser.add_argument(\"--num-envs\", type=int, default=4,\n","        help=\"the number of parallel game environments\")\n","    parser.add_argument(\"--num-steps\", type=int, default=128,\n","        help=\"the number of steps to run in each environment per policy rollout\")\n","    parser.add_argument(\"--anneal-lr\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n","        help=\"Toggle learning rate annealing for policy and value networks\")\n","    parser.add_argument(\"--gae\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n","        help=\"Use GAE for advantage computation\")\n","    parser.add_argument(\"--gamma\", type=float, default=0.99,\n","        help=\"the discount factor gamma\")\n","    parser.add_argument(\"--gae-lambda\", type=float, default=0.95,\n","        help=\"the lambda for the general advantage estimation\")\n","    parser.add_argument(\"--num-minibatches\", type=int, default=4,\n","        help=\"the number of mini-batches\")\n","    parser.add_argument(\"--update-epochs\", type=int, default=4,\n","        help=\"the K epochs to update the policy\")\n","    parser.add_argument(\"--norm-adv\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n","        help=\"Toggles advantages normalization\")\n","    parser.add_argument(\"--clip-coef\", type=float, default=0.2,\n","        help=\"the surrogate clipping coefficient\")\n","    parser.add_argument(\"--clip-vloss\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n","        help=\"Toggles whether or not to use a clipped loss for the value function, as per the paper.\")\n","    parser.add_argument(\"--ent-coef\", type=float, default=0.01,\n","        help=\"coefficient of the entropy\")\n","    parser.add_argument(\"--vf-coef\", type=float, default=0.5,\n","        help=\"coefficient of the value function\")\n","    parser.add_argument(\"--max-grad-norm\", type=float, default=0.5,\n","        help=\"the maximum norm for the gradient clipping\")\n","    parser.add_argument(\"--target-kl\", type=float, default=None,\n","        help=\"the target KL divergence threshold\")\n","    \n","    # Adding HuggingFace argument\n","    parser.add_argument(\"--repo-id\", type=str, default=\"ahma1289/ppo-CartPole-v1\", help=\"id of the model repository from the Hugging Face Hub {username/repo_name}\")\n","\n","    args = parser.parse_args()\n","    args.batch_size = int(args.num_envs * args.num_steps)\n","    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n","    # fmt: on\n","    return args\n","\n","def package_to_hub(repo_id, \n","                model,\n","                hyperparameters,\n","                eval_env,\n","                video_fps=30,\n","                commit_message=\"Push agent to the Hub\",\n","                token= None,\n","                logs=None\n","                ):\n","  \"\"\"\n","  Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n","  This method does the complete pipeline:\n","  - It evaluates the model\n","  - It generates the model card\n","  - It generates a replay video of the agent\n","  - It pushes everything to the hub\n","  :param repo_id: id of the model repository from the Hugging Face Hub\n","  :param model: trained model\n","  :param eval_env: environment used to evaluate the agent\n","  :param fps: number of fps for rendering the video\n","  :param commit_message: commit message\n","  :param logs: directory on local machine of tensorboard logs you'd like to upload\n","  \"\"\"\n","  msg.info(\n","        \"This function will save, evaluate, generate a video of your agent, \"\n","        \"create a model card and push everything to the hub. \"\n","        \"It might take up to 1min. \\n \"\n","        \"This is a work in progress: if you encounter a bug, please open an issue.\"\n","    )\n","  # Step 1: Clone or create the repo\n","  repo_url = HfApi().create_repo(\n","        repo_id=repo_id,\n","        token=token,\n","        private=False,\n","        exist_ok=True,\n","    )\n","  \n","  with tempfile.TemporaryDirectory() as tmpdirname:\n","    tmpdirname = Path(tmpdirname)\n","\n","    # Step 2: Save the model\n","    torch.save(model.state_dict(), tmpdirname / \"model.pt\")\n","  \n","    # Step 3: Evaluate the model and build JSON\n","    mean_reward, std_reward = _evaluate_agent(eval_env, \n","                                           10, \n","                                           model)\n","\n","    # First get datetime\n","    eval_datetime = datetime.datetime.now()\n","    eval_form_datetime = eval_datetime.isoformat()\n","\n","    evaluate_data = {\n","        \"env_id\": hyperparameters.env_id, \n","        \"mean_reward\": mean_reward,\n","        \"std_reward\": std_reward,\n","        \"n_evaluation_episodes\": 10,\n","        \"eval_datetime\": eval_form_datetime,\n","    }\n"," \n","    # Write a JSON file\n","    with open(tmpdirname / \"results.json\", \"w\") as outfile:\n","      json.dump(evaluate_data, outfile)\n","\n","    # Step 4: Generate a video\n","    video_path =  tmpdirname / \"replay.mp4\"\n","    record_video(eval_env, model, video_path, video_fps)\n","  \n","    # Step 5: Generate the model card\n","    generated_model_card, metadata = _generate_model_card(\"PPO\", hyperparameters.env_id, mean_reward, std_reward, hyperparameters)\n","    _save_model_card(tmpdirname, generated_model_card, metadata)\n","\n","    # Step 6: Add logs if needed\n","    if logs:\n","      _add_logdir(tmpdirname, Path(logs))\n","  \n","    msg.info(f\"Pushing repo {repo_id} to the Hugging Face Hub\")\n","  \n","    repo_url = upload_folder(\n","            repo_id=repo_id,\n","            folder_path=tmpdirname,\n","            path_in_repo=\"\",\n","            commit_message=commit_message,\n","            token=token,\n","        )\n","\n","    msg.info(f\"Your model is pushed to the Hub. You can view your model here: {repo_url}\")\n","  return repo_url\n","\n","def _evaluate_agent(env, n_eval_episodes, policy):\n","  \"\"\"\n","  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n","  :param env: The evaluation environment\n","  :param n_eval_episodes: Number of episode to evaluate the agent\n","  :param policy: The agent\n","  \"\"\"\n","  episode_rewards = []\n","  for episode in range(n_eval_episodes):\n","    state = env.reset()\n","    step = 0\n","    done = False\n","    total_rewards_ep = 0\n","    \n","    while done is False:\n","      state = torch.Tensor(state).to(device)\n","      action, _, _, _ = policy.get_action_and_value(state)\n","      new_state, reward, done, info = env.step(action.cpu().numpy())\n","      total_rewards_ep += reward    \n","      if done:\n","        break\n","      state = new_state\n","    episode_rewards.append(total_rewards_ep)\n","  mean_reward = np.mean(episode_rewards)\n","  std_reward = np.std(episode_rewards)\n","\n","  return mean_reward, std_reward\n","\n","\n","def record_video(env, policy, out_directory, fps=30):\n","  images = []  \n","  done = False\n","  state = env.reset()\n","  img = env.render(mode='rgb_array')\n","  images.append(img)\n","  while not done:\n","    state = torch.Tensor(state).to(device)\n","    # Take the action (index) that have the maximum expected future reward given that state\n","    action, _, _, _  = policy.get_action_and_value(state)\n","    state, reward, done, info = env.step(action.cpu().numpy()) # We directly put next_state = state for recording logic\n","    img = env.render(mode='rgb_array')\n","    images.append(img)\n","  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n","\n","\n","def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n","  \"\"\"\n","  Generate the model card for the Hub\n","  :param model_name: name of the model\n","  :env_id: name of the environment\n","  :mean_reward: mean reward of the agent\n","  :std_reward: standard deviation of the mean reward of the agent\n","  :hyperparameters: training arguments\n","  \"\"\"\n","  # Step 1: Select the tags\n","  metadata = generate_metadata(model_name, env_id, mean_reward, std_reward)\n","\n","  # Transform the hyperparams namespace to string\n","  converted_dict = vars(hyperparameters)\n","  converted_str = str(converted_dict)\n","  converted_str = converted_str.split(\", \")\n","  converted_str = '\\n'.join(converted_str)\n"," \n","  # Step 2: Generate the model card\n","  model_card = f\"\"\"\n","  # PPO Agent Playing {env_id}\n","\n","  This is a trained model of a PPO agent playing {env_id}.\n","    \n","  # Hyperparameters\n","  ```python\n","  {converted_str}\n","  ```\n","  \"\"\"\n","  return model_card, metadata\n","\n","def generate_metadata(model_name, env_id, mean_reward, std_reward):\n","  \"\"\"\n","  Define the tags for the model card\n","  :param model_name: name of the model\n","  :param env_id: name of the environment\n","  :mean_reward: mean reward of the agent\n","  :std_reward: standard deviation of the mean reward of the agent\n","  \"\"\"\n","  metadata = {}\n","  metadata[\"tags\"] = [\n","        env_id,\n","        \"ppo\",\n","        \"deep-reinforcement-learning\",\n","        \"reinforcement-learning\",\n","        \"custom-implementation\",\n","        \"deep-rl-course\"\n","  ]\n","\n","  # Add metrics\n","  eval = metadata_eval_result(\n","      model_pretty_name=model_name,\n","      task_pretty_name=\"reinforcement-learning\",\n","      task_id=\"reinforcement-learning\",\n","      metrics_pretty_name=\"mean_reward\",\n","      metrics_id=\"mean_reward\",\n","      metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n","      dataset_pretty_name=env_id,\n","      dataset_id=env_id,\n","  )\n","\n","  # Merges both dictionaries\n","  metadata = {**metadata, **eval}\n","\n","  return metadata\n","\n","def _save_model_card(local_path, generated_model_card, metadata):\n","    \"\"\"Saves a model card for the repository.\n","    :param local_path: repository directory\n","    :param generated_model_card: model card generated by _generate_model_card()\n","    :param metadata: metadata\n","    \"\"\"\n","    readme_path = local_path / \"README.md\"\n","    readme = \"\"\n","    if readme_path.exists():\n","        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n","            readme = f.read()\n","    else:\n","        readme = generated_model_card\n","\n","    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n","        f.write(readme)\n","\n","    # Save our metrics to Readme metadata\n","    metadata_save(readme_path, metadata)\n","\n","def _add_logdir(local_path: Path, logdir: Path):\n","  \"\"\"Adds a logdir to the repository.\n","  :param local_path: repository directory\n","  :param logdir: logdir directory\n","  \"\"\"\n","  if logdir.exists() and logdir.is_dir():\n","    # Add the logdir to the repository under new dir called logs\n","    repo_logdir = local_path / \"logs\"\n","    \n","    # Delete current logs if they exist\n","    if repo_logdir.exists():\n","      shutil.rmtree(repo_logdir)\n","\n","    # Copy logdir into repo logdir\n","    shutil.copytree(logdir, repo_logdir)\n","\n","def make_env(env_id, seed, idx, capture_video, run_name):\n","    def thunk():\n","        env = gym.make(env_id)\n","        env = gym.wrappers.RecordEpisodeStatistics(env)\n","        if capture_video:\n","            if idx == 0:\n","                env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n","        env.seed(seed)\n","        env.action_space.seed(seed)\n","        env.observation_space.seed(seed)\n","        return env\n","\n","    return thunk\n","\n","\n","def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n","    torch.nn.init.orthogonal_(layer.weight, std)\n","    torch.nn.init.constant_(layer.bias, bias_const)\n","    return layer\n","\n","\n","class Agent(nn.Module):\n","    def __init__(self, envs):\n","        super().__init__()\n","        self.critic = nn.Sequential(\n","            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n","            nn.Tanh(),\n","            layer_init(nn.Linear(64, 64)),\n","            nn.Tanh(),\n","            layer_init(nn.Linear(64, 1), std=1.0),\n","        )\n","        self.actor = nn.Sequential(\n","            layer_init(nn.Linear(np.array(envs.single_observation_space.shape).prod(), 64)),\n","            nn.Tanh(),\n","            layer_init(nn.Linear(64, 64)),\n","            nn.Tanh(),\n","            layer_init(nn.Linear(64, envs.single_action_space.n), std=0.01),\n","        )\n","\n","    def get_value(self, x):\n","        return self.critic(x)\n","\n","    def get_action_and_value(self, x, action=None):\n","        logits = self.actor(x)\n","        probs = Categorical(logits=logits)\n","        if action is None:\n","            action = probs.sample()\n","        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n","\n","\n","if __name__ == \"__main__\":\n","    args = parse_args()\n","    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n","    if args.track:\n","        import wandb\n","\n","        wandb.init(\n","            project=args.wandb_project_name,\n","            entity=args.wandb_entity,\n","            sync_tensorboard=True,\n","            config=vars(args),\n","            name=run_name,\n","            monitor_gym=True,\n","            save_code=True,\n","        )\n","    writer = SummaryWriter(f\"runs/{run_name}\")\n","    writer.add_text(\n","        \"hyperparameters\",\n","        \"|param|value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n","    )\n","\n","    # TRY NOT TO MODIFY: seeding\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.backends.cudnn.deterministic = args.torch_deterministic\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n","\n","    # env setup\n","    envs = gym.vector.SyncVectorEnv(\n","        [make_env(args.env_id, args.seed + i, i, args.capture_video, run_name) for i in range(args.num_envs)]\n","    )\n","    assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\"\n","\n","    agent = Agent(envs).to(device)\n","    optimizer = optim.Adam(agent.parameters(), lr=args.learning_rate, eps=1e-5)\n","\n","    # ALGO Logic: Storage setup\n","    obs = torch.zeros((args.num_steps, args.num_envs) + envs.single_observation_space.shape).to(device)\n","    actions = torch.zeros((args.num_steps, args.num_envs) + envs.single_action_space.shape).to(device)\n","    logprobs = torch.zeros((args.num_steps, args.num_envs)).to(device)\n","    rewards = torch.zeros((args.num_steps, args.num_envs)).to(device)\n","    dones = torch.zeros((args.num_steps, args.num_envs)).to(device)\n","    values = torch.zeros((args.num_steps, args.num_envs)).to(device)\n","\n","    # TRY NOT TO MODIFY: start the game\n","    global_step = 0\n","    start_time = time.time()\n","    next_obs = torch.Tensor(envs.reset()).to(device)\n","    next_done = torch.zeros(args.num_envs).to(device)\n","    num_updates = args.total_timesteps // args.batch_size\n","\n","    for update in range(1, num_updates + 1):\n","        # Annealing the rate if instructed to do so.\n","        if args.anneal_lr:\n","            frac = 1.0 - (update - 1.0) / num_updates\n","            lrnow = frac * args.learning_rate\n","            optimizer.param_groups[0][\"lr\"] = lrnow\n","\n","        for step in range(0, args.num_steps):\n","            global_step += 1 * args.num_envs\n","            obs[step] = next_obs\n","            dones[step] = next_done\n","\n","            # ALGO LOGIC: action logic\n","            with torch.no_grad():\n","                action, logprob, _, value = agent.get_action_and_value(next_obs)\n","                values[step] = value.flatten()\n","            actions[step] = action\n","            logprobs[step] = logprob\n","\n","            # TRY NOT TO MODIFY: execute the game and log data.\n","            next_obs, reward, done, info = envs.step(action.cpu().numpy())\n","            rewards[step] = torch.tensor(reward).to(device).view(-1)\n","            next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n","\n","            for item in info:\n","                if \"episode\" in item.keys():\n","                    print(f\"global_step={global_step}, episodic_return={item['episode']['r']}\")\n","                    writer.add_scalar(\"charts/episodic_return\", item[\"episode\"][\"r\"], global_step)\n","                    writer.add_scalar(\"charts/episodic_length\", item[\"episode\"][\"l\"], global_step)\n","                    break\n","\n","        # bootstrap value if not done\n","        with torch.no_grad():\n","            next_value = agent.get_value(next_obs).reshape(1, -1)\n","            if args.gae:\n","                advantages = torch.zeros_like(rewards).to(device)\n","                lastgaelam = 0\n","                for t in reversed(range(args.num_steps)):\n","                    if t == args.num_steps - 1:\n","                        nextnonterminal = 1.0 - next_done\n","                        nextvalues = next_value\n","                    else:\n","                        nextnonterminal = 1.0 - dones[t + 1]\n","                        nextvalues = values[t + 1]\n","                    delta = rewards[t] + args.gamma * nextvalues * nextnonterminal - values[t]\n","                    advantages[t] = lastgaelam = delta + args.gamma * args.gae_lambda * nextnonterminal * lastgaelam\n","                returns = advantages + values\n","            else:\n","                returns = torch.zeros_like(rewards).to(device)\n","                for t in reversed(range(args.num_steps)):\n","                    if t == args.num_steps - 1:\n","                        nextnonterminal = 1.0 - next_done\n","                        next_return = next_value\n","                    else:\n","                        nextnonterminal = 1.0 - dones[t + 1]\n","                        next_return = returns[t + 1]\n","                    returns[t] = rewards[t] + args.gamma * nextnonterminal * next_return\n","                advantages = returns - values\n","\n","        # flatten the batch\n","        b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n","        b_logprobs = logprobs.reshape(-1)\n","        b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n","        b_advantages = advantages.reshape(-1)\n","        b_returns = returns.reshape(-1)\n","        b_values = values.reshape(-1)\n","\n","        # Optimizing the policy and value network\n","        b_inds = np.arange(args.batch_size)\n","        clipfracs = []\n","        for epoch in range(args.update_epochs):\n","            np.random.shuffle(b_inds)\n","            for start in range(0, args.batch_size, args.minibatch_size):\n","                end = start + args.minibatch_size\n","                mb_inds = b_inds[start:end]\n","\n","                _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n","                logratio = newlogprob - b_logprobs[mb_inds]\n","                ratio = logratio.exp()\n","\n","                with torch.no_grad():\n","                    # calculate approx_kl http://joschu.net/blog/kl-approx.html\n","                    old_approx_kl = (-logratio).mean()\n","                    approx_kl = ((ratio - 1) - logratio).mean()\n","                    clipfracs += [((ratio - 1.0).abs() > args.clip_coef).float().mean().item()]\n","\n","                mb_advantages = b_advantages[mb_inds]\n","                if args.norm_adv:\n","                    mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n","\n","                # Policy loss\n","                pg_loss1 = -mb_advantages * ratio\n","                pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - args.clip_coef, 1 + args.clip_coef)\n","                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n","\n","                # Value loss\n","                newvalue = newvalue.view(-1)\n","                if args.clip_vloss:\n","                    v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n","                    v_clipped = b_values[mb_inds] + torch.clamp(\n","                        newvalue - b_values[mb_inds],\n","                        -args.clip_coef,\n","                        args.clip_coef,\n","                    )\n","                    v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n","                    v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n","                    v_loss = 0.5 * v_loss_max.mean()\n","                else:\n","                    v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n","\n","                entropy_loss = entropy.mean()\n","                loss = pg_loss - args.ent_coef * entropy_loss + v_loss * args.vf_coef\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                nn.utils.clip_grad_norm_(agent.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","\n","            if args.target_kl is not None:\n","                if approx_kl > args.target_kl:\n","                    break\n","\n","        y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n","        var_y = np.var(y_true)\n","        explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n","\n","        # TRY NOT TO MODIFY: record rewards for plotting purposes\n","        writer.add_scalar(\"charts/learning_rate\", optimizer.param_groups[0][\"lr\"], global_step)\n","        writer.add_scalar(\"losses/value_loss\", v_loss.item(), global_step)\n","        writer.add_scalar(\"losses/policy_loss\", pg_loss.item(), global_step)\n","        writer.add_scalar(\"losses/entropy\", entropy_loss.item(), global_step)\n","        writer.add_scalar(\"losses/old_approx_kl\", old_approx_kl.item(), global_step)\n","        writer.add_scalar(\"losses/approx_kl\", approx_kl.item(), global_step)\n","        writer.add_scalar(\"losses/clipfrac\", np.mean(clipfracs), global_step)\n","        writer.add_scalar(\"losses/explained_variance\", explained_var, global_step)\n","        print(\"SPS:\", int(global_step / (time.time() - start_time)))\n","        writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n","\n","    envs.close()\n","    writer.close()\n","\n","    # Create the evaluation environment\n","    eval_env = gym.make(args.env_id)\n","\n","    package_to_hub(repo_id = args.repo_id,\n","                model = agent, # The model we want to save\n","                hyperparameters = args,\n","                eval_env = gym.make(args.env_id),\n","                logs= f\"runs/{run_name}\",\n","                )\n","    "]},{"cell_type":"markdown","metadata":{"id":"JquRrWytA6eo"},"source":["To be able to share your model with the community there are three more steps to follow:\n","\n","1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n","\n","2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n","- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n","\n","<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n","\n","- Copy the token \n","- Run the cell below and paste the token"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"GZiFBBlzxzxY","colab":{"base_uri":"https://localhost:8080/","height":331,"referenced_widgets":["e0adc9f92fef465ba2193fe9edca6519","73b5af72222b422d933dd7532cd67834","d7bbd6b8c51b41d5ac9af290955a3196","c16e816bd3f94eaea040ed4565981747","e42744f31eb345dfa612e642e28489f2","718dd093a6214972b925370af8622d7d","697969006d7b47f6a875a53a04a922d3","e02e330103a04c9db94beb86b7902991","5d8ddaa2ba7f45f986fd7f60cd5143a8","870f13ef760b4fb899b2760852e5f59d","b15491dd899247c6800f0d32f6141ec4","674c64d1e71144a4b7f8c538192474dd","545230d1f60548d8ba9ad6f1185a6755","6082fc5b3f7b4ec0b052d0f5826bc828","0e015cfe2afb43bfb9c4215df5e99c44","4da17a40638b49e19bb26249690c5bd6","0d6ab09a77824ea4bd4849fecc8b0349"]},"executionInfo":{"status":"ok","timestamp":1679055618450,"user_tz":-60,"elapsed":257,"user":{"displayName":"Ahmad Alis","userId":"00720204365856394994"}},"outputId":"146f2bfb-17ea-443e-c211-50a25d3d57c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid.\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import notebook_login\n","notebook_login()\n","!git config --global credential.helper store"]},{"cell_type":"markdown","metadata":{"id":"_tsf2uv0g_4p"},"source":["If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"]},{"cell_type":"markdown","metadata":{"id":"jRqkGvk7pFQ6"},"source":["## Let's start the training üî•\n","- Now that you've coded from scratch PPO and added the Hugging Face Integration, we're ready to start the training üî•"]},{"cell_type":"markdown","metadata":{"id":"0tmEArP8ug2l"},"source":["- First, you need to copy all your code to a file you create called `ppo.py`"]},{"cell_type":"markdown","source":["<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/step1.png\" alt=\"PPO\"/>"],"metadata":{"id":"Sq0My0LOjPYR"}},{"cell_type":"markdown","source":["<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/step2.png\" alt=\"PPO\"/>"],"metadata":{"id":"A8C-Q5ZyjUe3"}},{"cell_type":"markdown","metadata":{"id":"VrS80GmMu_j5"},"source":["- Now we just need to run this python script using `python <name-of-python-script>.py` with the additional parameters we defined with `argparse`\n","\n","- You should modify more hyperparameters otherwise the training will not be super stable."]},{"cell_type":"code","source":["!python ppo.py --env-id=\"LunarLander-v2\" --repo-id=\"ahmad1289/ppo-CartPole-v1\" --total-timesteps=1000000"],"metadata":{"id":"KXLih6mKseBs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2be59968-c19f-4a8e-c813-5f4062e87e50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-17 12:20:50.631017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-17 12:20:51.687126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-17 12:20:51.687256: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n","2023-03-17 12:20:51.687271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","global_step=256, episodic_return=-107.11105346679688\n","global_step=300, episodic_return=-19.296920776367188\n","global_step=344, episodic_return=-206.24185180664062\n","SPS: 142\n","global_step=660, episodic_return=-123.17979431152344\n","global_step=680, episodic_return=-136.30296325683594\n","global_step=688, episodic_return=-257.21185302734375\n","global_step=780, episodic_return=33.70072937011719\n","global_step=896, episodic_return=-224.0498046875\n","SPS: 261\n","global_step=1124, episodic_return=-145.89602661132812\n","global_step=1156, episodic_return=-103.19561767578125\n","global_step=1224, episodic_return=-83.24772644042969\n","global_step=1244, episodic_return=-115.58294677734375\n","global_step=1400, episodic_return=-181.16390991210938\n","global_step=1520, episodic_return=-148.76519775390625\n","SPS: 361\n","global_step=1568, episodic_return=-113.75044250488281\n","global_step=1580, episodic_return=-101.87467956542969\n","global_step=1856, episodic_return=-202.6699981689453\n","global_step=1864, episodic_return=-75.86795806884766\n","global_step=1924, episodic_return=-334.7403564453125\n","global_step=1932, episodic_return=-295.2470703125\n","SPS: 444\n","global_step=2120, episodic_return=-102.56775665283203\n","global_step=2180, episodic_return=-49.64466094970703\n","global_step=2260, episodic_return=-109.91690826416016\n","global_step=2340, episodic_return=-214.756591796875\n","global_step=2484, episodic_return=-440.2062683105469\n","global_step=2528, episodic_return=-199.6612091064453\n","SPS: 516\n","global_step=2720, episodic_return=-414.2238464355469\n","global_step=2724, episodic_return=13.301925659179688\n","global_step=2868, episodic_return=-126.05977630615234\n","global_step=2936, episodic_return=-316.94940185546875\n","global_step=3004, episodic_return=-66.40597534179688\n","global_step=3040, episodic_return=-335.4903564453125\n","SPS: 580\n","global_step=3228, episodic_return=-48.3065185546875\n","global_step=3296, episodic_return=-215.32606506347656\n","global_step=3336, episodic_return=-128.67674255371094\n","global_step=3544, episodic_return=-38.28224182128906\n","SPS: 637\n","global_step=3668, episodic_return=-394.5766296386719\n","global_step=3708, episodic_return=-77.75881958007812\n","global_step=3712, episodic_return=-73.90593719482422\n","global_step=3844, episodic_return=-82.37982940673828\n","global_step=3960, episodic_return=-121.69532012939453\n","global_step=4044, episodic_return=-392.2916259765625\n","SPS: 687\n","global_step=4156, episodic_return=-101.88875579833984\n","global_step=4232, episodic_return=-250.00979614257812\n","global_step=4288, episodic_return=-88.20660400390625\n","global_step=4400, episodic_return=-125.62055206298828\n","global_step=4424, episodic_return=-96.95531463623047\n","SPS: 732\n","global_step=4684, episodic_return=-189.22067260742188\n","global_step=4716, episodic_return=-122.91136169433594\n","global_step=4748, episodic_return=-155.34591674804688\n","global_step=4768, episodic_return=-330.44818115234375\n","global_step=4988, episodic_return=-120.857177734375\n","global_step=5072, episodic_return=-338.4581298828125\n","SPS: 758\n","global_step=5200, episodic_return=-182.95941162109375\n","global_step=5300, episodic_return=-99.30015563964844\n","global_step=5404, episodic_return=-113.6374740600586\n","global_step=5464, episodic_return=-202.71298217773438\n","global_step=5628, episodic_return=-115.72404479980469\n","SPS: 780\n","global_step=5660, episodic_return=-26.089393615722656\n","global_step=5740, episodic_return=-85.72736358642578\n","global_step=5764, episodic_return=-447.7378234863281\n","global_step=5860, episodic_return=-113.33812713623047\n","global_step=6040, episodic_return=-315.2159423828125\n","global_step=6056, episodic_return=-103.71420288085938\n","global_step=6128, episodic_return=-92.06489562988281\n","SPS: 802\n","global_step=6276, episodic_return=-520.1416015625\n","global_step=6392, episodic_return=-115.34319305419922\n","global_step=6576, episodic_return=-105.23705291748047\n","global_step=6580, episodic_return=-109.29491424560547\n","global_step=6616, episodic_return=-254.61767578125\n","SPS: 819\n","global_step=6680, episodic_return=-132.50311279296875\n","global_step=6868, episodic_return=-136.72158813476562\n","global_step=6960, episodic_return=-91.60164642333984\n","global_step=7028, episodic_return=-244.34207153320312\n","global_step=7060, episodic_return=-343.25030517578125\n","global_step=7156, episodic_return=-71.51030731201172\n","SPS: 833\n","global_step=7284, episodic_return=-57.42170715332031\n","global_step=7296, episodic_return=-89.705078125\n","global_step=7488, episodic_return=-116.675537109375\n","global_step=7584, episodic_return=-117.28253173828125\n","global_step=7660, episodic_return=-361.6178283691406\n","SPS: 841\n","global_step=7704, episodic_return=-156.80581665039062\n","global_step=7764, episodic_return=-204.2293701171875\n","global_step=8004, episodic_return=-200.41554260253906\n","global_step=8108, episodic_return=-304.21722412109375\n","global_step=8164, episodic_return=-144.38119506835938\n","SPS: 848\n","global_step=8248, episodic_return=-49.153297424316406\n","global_step=8516, episodic_return=-230.88522338867188\n","global_step=8600, episodic_return=-186.08871459960938\n","global_step=8680, episodic_return=-195.3684844970703\n","SPS: 853\n","global_step=8736, episodic_return=-100.12760162353516\n","global_step=8932, episodic_return=-93.78307342529297\n","global_step=8972, episodic_return=-278.335693359375\n","global_step=9080, episodic_return=-115.59226989746094\n","global_step=9128, episodic_return=-82.81542205810547\n","SPS: 859\n","global_step=9432, episodic_return=-346.1053466796875\n","global_step=9460, episodic_return=-252.77871704101562\n","global_step=9508, episodic_return=-124.59001922607422\n","global_step=9560, episodic_return=-132.7996826171875\n","SPS: 879\n","global_step=9820, episodic_return=-337.9059753417969\n","global_step=9824, episodic_return=-113.26995849609375\n","global_step=9900, episodic_return=-104.80610656738281\n","global_step=10032, episodic_return=-71.73346710205078\n","global_step=10212, episodic_return=-333.35955810546875\n","SPS: 897\n","global_step=10256, episodic_return=-464.600830078125\n","global_step=10308, episodic_return=-357.74822998046875\n","global_step=10436, episodic_return=-353.6765441894531\n","global_step=10552, episodic_return=-127.45819091796875\n","global_step=10572, episodic_return=-286.2156677246094\n","global_step=10600, episodic_return=-87.2706069946289\n","SPS: 915\n","global_step=10764, episodic_return=-149.94827270507812\n","global_step=10884, episodic_return=-111.49928283691406\n","global_step=10984, episodic_return=-384.2238464355469\n","global_step=11028, episodic_return=-117.40432739257812\n","global_step=11164, episodic_return=-134.4832763671875\n","global_step=11192, episodic_return=-87.90584564208984\n","global_step=11228, episodic_return=-72.90950775146484\n","SPS: 930\n","global_step=11304, episodic_return=-71.91184997558594\n","global_step=11536, episodic_return=-222.8402557373047\n","global_step=11576, episodic_return=-299.0723876953125\n","global_step=11616, episodic_return=-137.78903198242188\n","global_step=11708, episodic_return=-67.21147155761719\n","SPS: 946\n","global_step=11896, episodic_return=-124.46470642089844\n","global_step=11904, episodic_return=-142.21469116210938\n","global_step=12008, episodic_return=-253.21546936035156\n","global_step=12212, episodic_return=-68.42216491699219\n","SPS: 961\n","global_step=12312, episodic_return=-60.91999053955078\n","global_step=12316, episodic_return=-109.99964141845703\n","global_step=12480, episodic_return=-286.0419921875\n","global_step=12488, episodic_return=-244.77999877929688\n","global_step=12696, episodic_return=-581.8162231445312\n","global_step=12708, episodic_return=-78.07351684570312\n","SPS: 974\n","global_step=12960, episodic_return=-74.2369613647461\n","global_step=13028, episodic_return=-541.398193359375\n","global_step=13064, episodic_return=-203.3784942626953\n","global_step=13108, episodic_return=-251.12298583984375\n","global_step=13272, episodic_return=-136.38531494140625\n","SPS: 987\n","global_step=13492, episodic_return=-177.0853271484375\n","global_step=13520, episodic_return=-74.85309600830078\n","global_step=13576, episodic_return=-255.93487548828125\n","global_step=13808, episodic_return=-239.08319091796875\n","SPS: 1000\n","global_step=13876, episodic_return=-171.95802307128906\n","global_step=13908, episodic_return=-395.2411193847656\n","global_step=13996, episodic_return=-197.5697784423828\n","global_step=14200, episodic_return=-225.00051879882812\n","global_step=14268, episodic_return=-91.7869873046875\n","SPS: 1012\n","global_step=14368, episodic_return=-163.9781036376953\n","global_step=14480, episodic_return=-127.59345245361328\n","global_step=14500, episodic_return=-138.31414794921875\n","global_step=14620, episodic_return=-109.01521301269531\n","global_step=14780, episodic_return=-133.2493438720703\n","global_step=14832, episodic_return=-74.01701354980469\n","SPS: 1024\n","global_step=15004, episodic_return=-290.11541748046875\n","global_step=15096, episodic_return=-85.93318939208984\n","global_step=15168, episodic_return=-145.32041931152344\n","global_step=15176, episodic_return=-252.0869140625\n","SPS: 1035\n","global_step=15364, episodic_return=-102.97468566894531\n","global_step=15456, episodic_return=-131.90794372558594\n","global_step=15472, episodic_return=-132.4337158203125\n","global_step=15680, episodic_return=-258.8457336425781\n","global_step=15744, episodic_return=-94.747314453125\n","SPS: 1045\n","global_step=15884, episodic_return=-305.07855224609375\n","global_step=15988, episodic_return=-135.17396545410156\n","global_step=15992, episodic_return=-99.00052642822266\n","global_step=16040, episodic_return=-79.30482482910156\n","global_step=16180, episodic_return=-73.85527038574219\n","global_step=16352, episodic_return=-125.27078247070312\n","global_step=16380, episodic_return=-107.56729888916016\n","SPS: 1055\n","global_step=16428, episodic_return=-136.9891815185547\n","global_step=16692, episodic_return=-240.4500732421875\n","global_step=16780, episodic_return=-282.10150146484375\n","global_step=16880, episodic_return=-375.2666931152344\n","SPS: 1065\n","global_step=16996, episodic_return=-125.64649963378906\n","global_step=17008, episodic_return=-297.8035583496094\n","global_step=17272, episodic_return=-52.650169372558594\n","global_step=17280, episodic_return=-118.9052963256836\n","global_step=17312, episodic_return=-117.89693450927734\n","SPS: 1074\n","global_step=17612, episodic_return=-193.73162841796875\n","global_step=17776, episodic_return=-287.91839599609375\n","global_step=17856, episodic_return=-150.9714813232422\n","global_step=17888, episodic_return=-324.7605895996094\n","SPS: 1082\n","global_step=17932, episodic_return=-63.18028259277344\n","global_step=18340, episodic_return=-182.88967895507812\n","global_step=18356, episodic_return=-113.47100067138672\n","global_step=18404, episodic_return=-272.5122375488281\n","SPS: 1089\n","global_step=18456, episodic_return=-65.078125\n","global_step=18680, episodic_return=-232.2474365234375\n","global_step=18728, episodic_return=-105.74876403808594\n","global_step=18776, episodic_return=-80.78038024902344\n","SPS: 1097\n","global_step=18948, episodic_return=-67.77272033691406\n","global_step=18988, episodic_return=-263.9010009765625\n","global_step=19244, episodic_return=-110.91828918457031\n","global_step=19284, episodic_return=-132.46279907226562\n","global_step=19296, episodic_return=-274.74322509765625\n","SPS: 1104\n","global_step=19460, episodic_return=-249.44403076171875\n","global_step=19572, episodic_return=-93.05599975585938\n","global_step=19640, episodic_return=-203.95556640625\n","global_step=19860, episodic_return=-222.63418579101562\n","global_step=19872, episodic_return=-130.13526916503906\n","SPS: 1111\n","global_step=19980, episodic_return=-122.28659057617188\n","global_step=20040, episodic_return=2.0678939819335938\n","global_step=20332, episodic_return=-60.836788177490234\n","global_step=20360, episodic_return=-138.17791748046875\n","global_step=20372, episodic_return=-120.8714599609375\n","SPS: 1119\n","global_step=20492, episodic_return=-379.1253967285156\n","global_step=20700, episodic_return=-136.31094360351562\n","global_step=20780, episodic_return=-142.2396697998047\n","global_step=20836, episodic_return=-108.95751953125\n","global_step=20960, episodic_return=-38.25511932373047\n","SPS: 1126\n","global_step=21048, episodic_return=-36.49049377441406\n","global_step=21152, episodic_return=-92.20408630371094\n","global_step=21316, episodic_return=-273.74151611328125\n","global_step=21360, episodic_return=-253.259765625\n","global_step=21420, episodic_return=-104.17923736572266\n","SPS: 1132\n","global_step=21596, episodic_return=-132.9306182861328\n","global_step=21636, episodic_return=-76.92530059814453\n","global_step=21804, episodic_return=-132.35350036621094\n","global_step=21852, episodic_return=-188.57998657226562\n","global_step=21984, episodic_return=-107.9434814453125\n","global_step=21992, episodic_return=-87.34768676757812\n","SPS: 1138\n","global_step=22156, episodic_return=-21.434547424316406\n","global_step=22328, episodic_return=-88.75692749023438\n","global_step=22332, episodic_return=-90.54832458496094\n","global_step=22392, episodic_return=-151.87353515625\n","SPS: 1145\n","global_step=22696, episodic_return=-137.49819946289062\n","global_step=22856, episodic_return=-94.6905746459961\n","global_step=22920, episodic_return=-116.67560577392578\n","global_step=22948, episodic_return=-98.93202209472656\n","global_step=23008, episodic_return=-76.868896484375\n","SPS: 1150\n","global_step=23204, episodic_return=-97.02827453613281\n","global_step=23264, episodic_return=-113.90061950683594\n","global_step=23472, episodic_return=-292.93304443359375\n","SPS: 1156\n","global_step=23568, episodic_return=-64.48482513427734\n","global_step=23584, episodic_return=-117.68292999267578\n","global_step=23732, episodic_return=-154.91339111328125\n","global_step=23852, episodic_return=-78.71955871582031\n","global_step=23872, episodic_return=-155.59918212890625\n","SPS: 1161\n","global_step=24204, episodic_return=-188.015625\n","global_step=24260, episodic_return=-219.60992431640625\n","global_step=24280, episodic_return=-263.35577392578125\n","global_step=24388, episodic_return=-310.09423828125\n","global_step=24564, episodic_return=-269.9482421875\n","SPS: 1158\n","global_step=24608, episodic_return=-84.17097473144531\n","global_step=24676, episodic_return=-105.61982727050781\n","global_step=24928, episodic_return=-83.53611755371094\n","global_step=24968, episodic_return=-69.17129516601562\n","SPS: 1157\n","global_step=25188, episodic_return=-99.51102447509766\n","global_step=25296, episodic_return=-91.64083099365234\n","global_step=25300, episodic_return=-84.79642486572266\n","global_step=25476, episodic_return=-320.8990478515625\n","global_step=25576, episodic_return=-125.45500183105469\n","SPS: 1139\n","global_step=25656, episodic_return=-278.6244812011719\n","global_step=25824, episodic_return=-129.13902282714844\n","global_step=25928, episodic_return=-155.38792419433594\n","global_step=25996, episodic_return=-93.3887939453125\n","global_step=26040, episodic_return=-103.77667236328125\n","SPS: 1135\n","global_step=26128, episodic_return=-66.24397277832031\n","global_step=26336, episodic_return=-257.2554931640625\n","global_step=26428, episodic_return=-255.6353759765625\n","global_step=26512, episodic_return=-90.84329223632812\n","global_step=26544, episodic_return=-122.53532409667969\n","SPS: 1116\n","global_step=26776, episodic_return=-81.46806335449219\n","global_step=26788, episodic_return=-87.79517364501953\n","global_step=26836, episodic_return=-149.34597778320312\n","global_step=26896, episodic_return=-273.8236083984375\n","global_step=27028, episodic_return=-76.22708892822266\n","global_step=27092, episodic_return=-90.73298645019531\n","SPS: 1101\n","global_step=27160, episodic_return=-90.48179626464844\n","global_step=27348, episodic_return=-320.3297424316406\n","global_step=27408, episodic_return=-166.57415771484375\n","global_step=27520, episodic_return=-160.27871704101562\n","global_step=27628, episodic_return=-407.3357849121094\n","SPS: 1098\n","global_step=27712, episodic_return=-90.40911865234375\n","global_step=27864, episodic_return=-33.89459228515625\n","global_step=27964, episodic_return=-152.77117919921875\n","global_step=27988, episodic_return=-91.16824340820312\n","global_step=28156, episodic_return=-221.24929809570312\n","SPS: 1097\n","global_step=28416, episodic_return=-241.81210327148438\n","global_step=28468, episodic_return=-260.66912841796875\n","global_step=28488, episodic_return=-150.41307067871094\n","global_step=28496, episodic_return=-27.935768127441406\n","SPS: 1102\n","global_step=28736, episodic_return=-67.0484619140625\n","global_step=28776, episodic_return=-79.31747436523438\n","global_step=28828, episodic_return=-106.0285873413086\n","global_step=28836, episodic_return=-80.41455841064453\n","global_step=29084, episodic_return=-145.60302734375\n","SPS: 1107\n","global_step=29208, episodic_return=-186.4559326171875\n","global_step=29260, episodic_return=-288.0331726074219\n","global_step=29364, episodic_return=-243.8065948486328\n","global_step=29520, episodic_return=-163.1580047607422\n","global_step=29644, episodic_return=-90.88644409179688\n","global_step=29684, episodic_return=-106.361572265625\n","SPS: 1112\n","global_step=29864, episodic_return=-135.59463500976562\n","global_step=30032, episodic_return=-155.5634307861328\n","global_step=30128, episodic_return=-211.9638671875\n","global_step=30176, episodic_return=-141.27035522460938\n","SPS: 1117\n","global_step=30424, episodic_return=-96.04360961914062\n","global_step=30528, episodic_return=-117.4754409790039\n","global_step=30548, episodic_return=-213.2022705078125\n","global_step=30608, episodic_return=-234.33856201171875\n","SPS: 1121\n","global_step=30828, episodic_return=-97.57093048095703\n","global_step=30832, episodic_return=-78.1630630493164\n","global_step=30876, episodic_return=-107.05514526367188\n","global_step=31080, episodic_return=-84.0921630859375\n","global_step=31112, episodic_return=-68.05689239501953\n","global_step=31204, episodic_return=-121.67613220214844\n","SPS: 1126\n","global_step=31328, episodic_return=-30.91252899169922\n","global_step=31416, episodic_return=-101.92388916015625\n","global_step=31472, episodic_return=-96.38523864746094\n","global_step=31596, episodic_return=-67.11810302734375\n","global_step=31696, episodic_return=-352.38592529296875\n","global_step=31700, episodic_return=-63.84499740600586\n","SPS: 1131\n","global_step=31772, episodic_return=-100.72793579101562\n","global_step=32020, episodic_return=-152.38787841796875\n","global_step=32028, episodic_return=-133.81491088867188\n","global_step=32152, episodic_return=-273.97369384765625\n","global_step=32164, episodic_return=-151.41680908203125\n","SPS: 1136\n","global_step=32304, episodic_return=-112.03240966796875\n","global_step=32324, episodic_return=-84.26956939697266\n","global_step=32436, episodic_return=-57.20603561401367\n","global_step=32556, episodic_return=-80.78349304199219\n","global_step=32632, episodic_return=-94.1290283203125\n","global_step=32636, episodic_return=-148.6773223876953\n","global_step=32728, episodic_return=-152.07566833496094\n","SPS: 1140\n","global_step=32968, episodic_return=-44.850868225097656\n","global_step=33000, episodic_return=-85.27570343017578\n","global_step=33088, episodic_return=-108.17433166503906\n","global_step=33228, episodic_return=-170.56687927246094\n","global_step=33280, episodic_return=-79.40938568115234\n","SPS: 1143\n","global_step=33284, episodic_return=-27.734420776367188\n","global_step=33372, episodic_return=-70.80712890625\n","global_step=33596, episodic_return=-148.9374542236328\n","global_step=33692, episodic_return=-85.71092987060547\n","SPS: 1146\n","global_step=33860, episodic_return=-121.0304183959961\n","global_step=33900, episodic_return=-191.05166625976562\n","global_step=33984, episodic_return=-105.86921691894531\n","global_step=34020, episodic_return=-16.098915100097656\n","global_step=34260, episodic_return=-99.2443618774414\n","SPS: 1150\n","global_step=34320, episodic_return=-210.71368408203125\n","global_step=34380, episodic_return=6.558891296386719\n","global_step=34432, episodic_return=-218.16232299804688\n","global_step=34584, episodic_return=-207.6747283935547\n","global_step=34692, episodic_return=-109.95063781738281\n","SPS: 1153\n","global_step=34836, episodic_return=-157.93724060058594\n","global_step=34988, episodic_return=-107.56266021728516\n","global_step=35000, episodic_return=-110.5851821899414\n","global_step=35044, episodic_return=-121.17755889892578\n","global_step=35220, episodic_return=-237.3741912841797\n","global_step=35280, episodic_return=-62.794403076171875\n","SPS: 1157\n","global_step=35364, episodic_return=-154.71974182128906\n","global_step=35368, episodic_return=-91.61202239990234\n","global_step=35552, episodic_return=-122.15827941894531\n","global_step=35656, episodic_return=-113.76548767089844\n","global_step=35804, episodic_return=-168.20510864257812\n","global_step=35832, episodic_return=-76.02194213867188\n","SPS: 1161\n","global_step=35936, episodic_return=-130.6999053955078\n","global_step=36008, episodic_return=-164.8309326171875\n","global_step=36112, episodic_return=-129.29641723632812\n","global_step=36216, episodic_return=-148.3300323486328\n","global_step=36344, episodic_return=-91.4212875366211\n","SPS: 1165\n","global_step=36440, episodic_return=-120.3929443359375\n","global_step=36484, episodic_return=-124.81015014648438\n","global_step=36548, episodic_return=-44.942771911621094\n","global_step=36644, episodic_return=-85.04176330566406\n","SPS: 1169\n","global_step=36888, episodic_return=-132.63661193847656\n","global_step=36912, episodic_return=-63.49312973022461\n","global_step=37112, episodic_return=-181.80584716796875\n","global_step=37176, episodic_return=-21.847305297851562\n","global_step=37316, episodic_return=-286.94024658203125\n","SPS: 1172\n","global_step=37392, episodic_return=-376.20635986328125\n","global_step=37568, episodic_return=-115.71443176269531\n","global_step=37676, episodic_return=-168.1828155517578\n","global_step=37844, episodic_return=-70.55497741699219\n","SPS: 1175\n","global_step=37900, episodic_return=-180.3125457763672\n","global_step=38048, episodic_return=-203.6334228515625\n","global_step=38072, episodic_return=-122.25553894042969\n","global_step=38176, episodic_return=-87.41851043701172\n","global_step=38344, episodic_return=-208.25595092773438\n","SPS: 1178\n","global_step=38432, episodic_return=-51.487056732177734\n","global_step=38604, episodic_return=-150.7621307373047\n","global_step=38704, episodic_return=-248.4801025390625\n","global_step=38708, episodic_return=-152.55844116210938\n","SPS: 1181\n","global_step=39004, episodic_return=-223.10308837890625\n","global_step=39032, episodic_return=-346.61358642578125\n","global_step=39152, episodic_return=-54.816951751708984\n","global_step=39304, episodic_return=-79.26614379882812\n","global_step=39312, episodic_return=-89.05908203125\n","global_step=39392, episodic_return=-117.56603240966797\n","SPS: 1184\n","global_step=39472, episodic_return=-54.76805877685547\n","global_step=39700, episodic_return=-132.25790405273438\n","global_step=39836, episodic_return=-154.69810485839844\n","SPS: 1187\n","global_step=40028, episodic_return=-323.50848388671875\n","global_step=40056, episodic_return=-69.10709381103516\n","global_step=40144, episodic_return=-198.49346923828125\n","global_step=40388, episodic_return=-59.474761962890625\n","global_step=40408, episodic_return=-165.4449920654297\n","SPS: 1190\n","global_step=40560, episodic_return=-304.4812927246094\n","global_step=40580, episodic_return=-153.13394165039062\n","global_step=40700, episodic_return=-98.96179962158203\n","global_step=40880, episodic_return=-72.15008544921875\n","global_step=40936, episodic_return=-61.42189025878906\n","SPS: 1192\n","global_step=40976, episodic_return=-225.64955139160156\n","global_step=41276, episodic_return=-133.79037475585938\n","global_step=41320, episodic_return=-63.107444763183594\n","global_step=41452, episodic_return=-253.4136505126953\n","SPS: 1195\n","global_step=41528, episodic_return=-255.98123168945312\n","global_step=41752, episodic_return=-172.16049194335938\n","global_step=41956, episodic_return=-287.19384765625\n","SPS: 1198\n","global_step=42004, episodic_return=-146.7786865234375\n","global_step=42048, episodic_return=-31.84417724609375\n","global_step=42116, episodic_return=-189.07557678222656\n","global_step=42280, episodic_return=-12.863487243652344\n","global_step=42308, episodic_return=-123.31131744384766\n","global_step=42440, episodic_return=-190.41188049316406\n","SPS: 1200\n","global_step=42516, episodic_return=-113.02198028564453\n","global_step=42572, episodic_return=-105.11866760253906\n","global_step=42596, episodic_return=-166.74087524414062\n","global_step=42860, episodic_return=-100.43899536132812\n","global_step=42884, episodic_return=-277.8388366699219\n","global_step=42944, episodic_return=-106.66751098632812\n","SPS: 1201\n","global_step=43140, episodic_return=-123.84922790527344\n","global_step=43180, episodic_return=-275.88287353515625\n","global_step=43424, episodic_return=-214.7061767578125\n","global_step=43440, episodic_return=-96.6064453125\n","SPS: 1199\n","global_step=43548, episodic_return=-107.25157165527344\n","global_step=43568, episodic_return=-117.40766906738281\n","global_step=43776, episodic_return=-70.32025146484375\n","global_step=43808, episodic_return=-153.83226013183594\n","global_step=43840, episodic_return=-124.45352172851562\n","global_step=43992, episodic_return=-134.13021850585938\n","SPS: 1198\n","global_step=44256, episodic_return=-187.11749267578125\n","global_step=44352, episodic_return=-97.7026138305664\n","global_step=44388, episodic_return=-68.72712707519531\n","SPS: 1197\n","global_step=44604, episodic_return=-162.91629028320312\n","global_step=44692, episodic_return=-86.0848617553711\n","global_step=44748, episodic_return=-127.40210723876953\n","global_step=44784, episodic_return=-13.099586486816406\n","global_step=44992, episodic_return=-69.52164459228516\n","global_step=45012, episodic_return=-246.4042510986328\n","global_step=45020, episodic_return=-104.04939270019531\n","SPS: 1195\n","global_step=45220, episodic_return=-126.83699035644531\n","global_step=45288, episodic_return=-84.36669921875\n","global_step=45480, episodic_return=-5.643775939941406\n","global_step=45532, episodic_return=-440.3807067871094\n","SPS: 1193\n","global_step=45644, episodic_return=-148.5723419189453\n","global_step=45744, episodic_return=-83.83805847167969\n","global_step=45868, episodic_return=-232.51962280273438\n","global_step=45872, episodic_return=-65.5771713256836\n","global_step=46040, episodic_return=-77.35469055175781\n","SPS: 1190\n","global_step=46264, episodic_return=-95.34362030029297\n","global_step=46276, episodic_return=-162.82125854492188\n","global_step=46352, episodic_return=-205.09524536132812\n","global_step=46524, episodic_return=-90.19325256347656\n","global_step=46576, episodic_return=-102.15860748291016\n","SPS: 1188\n","global_step=46672, episodic_return=-67.8291015625\n","global_step=46788, episodic_return=-173.43020629882812\n","global_step=46992, episodic_return=-15.802452087402344\n","SPS: 1185\n","global_step=47148, episodic_return=-87.99324035644531\n","global_step=47152, episodic_return=-346.6735534667969\n","global_step=47224, episodic_return=-77.28685760498047\n","global_step=47508, episodic_return=-64.57173156738281\n","global_step=47560, episodic_return=-136.9272918701172\n","SPS: 1184\n","global_step=47816, episodic_return=-81.08415222167969\n","global_step=47852, episodic_return=-38.38386154174805\n","global_step=47884, episodic_return=-84.43251037597656\n","SPS: 1186\n","global_step=48260, episodic_return=-51.324703216552734\n","global_step=48288, episodic_return=-60.84660720825195\n","global_step=48372, episodic_return=-143.2091064453125\n","global_step=48596, episodic_return=-88.7491683959961\n","SPS: 1188\n","global_step=48660, episodic_return=-195.85934448242188\n","global_step=48704, episodic_return=-99.97930145263672\n","global_step=48916, episodic_return=-127.40998077392578\n","global_step=49140, episodic_return=-184.12771606445312\n","SPS: 1191\n","global_step=49196, episodic_return=-170.52891540527344\n","global_step=49228, episodic_return=-243.6552734375\n","global_step=49312, episodic_return=-93.32714080810547\n","global_step=49488, episodic_return=-71.0181884765625\n","global_step=49516, episodic_return=-70.9183120727539\n","global_step=49608, episodic_return=-103.49452209472656\n","SPS: 1193\n","global_step=49808, episodic_return=-228.1370086669922\n","global_step=49888, episodic_return=-77.55905151367188\n","global_step=49980, episodic_return=-175.0208282470703\n","global_step=50036, episodic_return=-272.4007568359375\n","SPS: 1195\n","global_step=50332, episodic_return=-40.55459976196289\n","global_step=50444, episodic_return=-93.0532455444336\n","global_step=50460, episodic_return=-222.32318115234375\n","global_step=50488, episodic_return=-149.73106384277344\n","global_step=50620, episodic_return=-85.07119750976562\n","SPS: 1197\n","global_step=50796, episodic_return=-45.884952545166016\n","global_step=50844, episodic_return=-219.68011474609375\n","global_step=50968, episodic_return=-188.2442626953125\n","global_step=51012, episodic_return=-126.1266098022461\n","SPS: 1199\n","global_step=51248, episodic_return=-109.85587310791016\n","global_step=51264, episodic_return=-57.489803314208984\n","global_step=51312, episodic_return=-107.49169921875\n","global_step=51324, episodic_return=-96.09761810302734\n","global_step=51604, episodic_return=-73.28645324707031\n","global_step=51636, episodic_return=-129.7115478515625\n","global_step=51656, episodic_return=-82.24562072753906\n","SPS: 1202\n","global_step=51800, episodic_return=-83.00579833984375\n","global_step=52032, episodic_return=-99.8869400024414\n","global_step=52052, episodic_return=-170.3321533203125\n","global_step=52128, episodic_return=-69.235595703125\n","SPS: 1204\n","global_step=52284, episodic_return=-139.38401794433594\n","global_step=52564, episodic_return=-78.50699615478516\n","global_step=52568, episodic_return=-107.13453674316406\n","global_step=52580, episodic_return=-90.67063903808594\n","global_step=52660, episodic_return=-260.6934814453125\n","SPS: 1206\n","global_step=52916, episodic_return=-131.0741729736328\n","global_step=53060, episodic_return=-193.77828979492188\n","global_step=53068, episodic_return=-240.61468505859375\n","global_step=53176, episodic_return=-87.55430603027344\n","SPS: 1208\n","global_step=53380, episodic_return=-96.75415802001953\n","global_step=53480, episodic_return=-61.90244674682617\n","global_step=53488, episodic_return=-90.32535552978516\n","global_step=53688, episodic_return=-231.0459747314453\n","SPS: 1209\n","global_step=53868, episodic_return=-219.97218322753906\n","global_step=53932, episodic_return=-196.63795471191406\n","global_step=54012, episodic_return=-114.44462585449219\n","global_step=54124, episodic_return=-48.636474609375\n","SPS: 1212\n","global_step=54368, episodic_return=-84.55062866210938\n","global_step=54540, episodic_return=-76.5556411743164\n","global_step=54580, episodic_return=-309.0618896484375\n","global_step=54664, episodic_return=-363.74163818359375\n","global_step=54744, episodic_return=-73.84504699707031\n","SPS: 1213\n","global_step=54928, episodic_return=-128.28656005859375\n","global_step=54944, episodic_return=-127.40818786621094\n","global_step=54980, episodic_return=-72.60884094238281\n","global_step=55044, episodic_return=-74.55906677246094\n","global_step=55204, episodic_return=-103.93234252929688\n","global_step=55280, episodic_return=-31.394012451171875\n","SPS: 1216\n","global_step=55448, episodic_return=-59.79962158203125\n","global_step=55524, episodic_return=-210.90890502929688\n","global_step=55664, episodic_return=-97.00334930419922\n","global_step=55708, episodic_return=-104.69641876220703\n","SPS: 1218\n","global_step=55992, episodic_return=-64.15916442871094\n","global_step=56024, episodic_return=-55.691505432128906\n","global_step=56264, episodic_return=-61.53382873535156\n","global_step=56292, episodic_return=-238.96839904785156\n","SPS: 1220\n","global_step=56472, episodic_return=-80.98143005371094\n","global_step=56592, episodic_return=-89.68411254882812\n","global_step=56672, episodic_return=-140.55313110351562\n","global_step=56728, episodic_return=-59.795108795166016\n","SPS: 1222\n","global_step=56892, episodic_return=-103.79405975341797\n","global_step=57016, episodic_return=-76.0765380859375\n","global_step=57108, episodic_return=-186.49005126953125\n","global_step=57172, episodic_return=-77.79713439941406\n","global_step=57260, episodic_return=-124.4632339477539\n","global_step=57312, episodic_return=-80.6767807006836\n","SPS: 1224\n","global_step=57448, episodic_return=-100.10799407958984\n","global_step=57496, episodic_return=-139.95001220703125\n","global_step=57680, episodic_return=-83.75779724121094\n","global_step=57736, episodic_return=-53.665653228759766\n","SPS: 1226\n","global_step=57980, episodic_return=-42.32936096191406\n","global_step=58064, episodic_return=-50.87113571166992\n","global_step=58096, episodic_return=-158.49063110351562\n","global_step=58304, episodic_return=-267.6449890136719\n","SPS: 1227\n","global_step=58448, episodic_return=-173.18356323242188\n","global_step=58520, episodic_return=-100.66688537597656\n","global_step=58676, episodic_return=-132.1250457763672\n","global_step=58840, episodic_return=-107.32550048828125\n","SPS: 1229\n","global_step=58884, episodic_return=-148.82421875\n","global_step=59072, episodic_return=-156.3357391357422\n","global_step=59184, episodic_return=-71.46949005126953\n","global_step=59208, episodic_return=-111.53992462158203\n","global_step=59348, episodic_return=-68.57034301757812\n","SPS: 1230\n","global_step=59584, episodic_return=-57.10265350341797\n","global_step=59688, episodic_return=-83.773681640625\n","global_step=59856, episodic_return=-228.95278930664062\n","SPS: 1231\n","global_step=60180, episodic_return=-227.5247802734375\n","global_step=60192, episodic_return=-20.188491821289062\n","global_step=60256, episodic_return=-118.08493041992188\n","SPS: 1233\n","global_step=60548, episodic_return=-66.0777816772461\n","global_step=60628, episodic_return=-183.2039031982422\n","global_step=60672, episodic_return=-38.66986083984375\n","global_step=60824, episodic_return=-173.72084045410156\n","SPS: 1234\n","global_step=61056, episodic_return=-77.03572845458984\n","global_step=61208, episodic_return=-87.24579620361328\n","global_step=61388, episodic_return=-105.36776733398438\n","SPS: 1235\n","global_step=61644, episodic_return=-201.1156005859375\n","global_step=61712, episodic_return=-194.25350952148438\n","global_step=61732, episodic_return=-227.08892822265625\n","SPS: 1236\n","global_step=62048, episodic_return=-122.03968048095703\n","global_step=62128, episodic_return=-80.81298065185547\n","global_step=62272, episodic_return=-146.7281951904297\n","SPS: 1233\n","global_step=62472, episodic_return=-55.90925216674805\n","global_step=62632, episodic_return=-93.75062561035156\n","global_step=62776, episodic_return=-99.70869445800781\n","global_step=62880, episodic_return=-237.49044799804688\n","global_step=62916, episodic_return=-224.2386932373047\n","SPS: 1230\n","global_step=63024, episodic_return=-21.291824340820312\n","global_step=63288, episodic_return=-195.74586486816406\n","SPS: 1228\n","global_step=63536, episodic_return=-230.47747802734375\n","global_step=63712, episodic_return=-186.7541046142578\n","global_step=63888, episodic_return=-422.59234619140625\n","global_step=63972, episodic_return=-52.64054489135742\n","global_step=63996, episodic_return=-140.54302978515625\n","SPS: 1225\n","global_step=64472, episodic_return=-91.50067138671875\n","SPS: 1221\n","global_step=64564, episodic_return=-235.25869750976562\n","global_step=64676, episodic_return=-395.78814697265625\n","SPS: 1216\n","global_step=65040, episodic_return=-51.094444274902344\n","global_step=65112, episodic_return=-133.490478515625\n","global_step=65176, episodic_return=-281.1119689941406\n","global_step=65260, episodic_return=-352.99871826171875\n","SPS: 1212\n","global_step=65548, episodic_return=-214.0514373779297\n","global_step=65696, episodic_return=-341.59344482421875\n","global_step=65808, episodic_return=-63.7707405090332\n","global_step=65912, episodic_return=-12.694869995117188\n","SPS: 1209\n","global_step=66120, episodic_return=-65.31240844726562\n","global_step=66388, episodic_return=-42.73978805541992\n","global_step=66420, episodic_return=-126.41177368164062\n","global_step=66464, episodic_return=-181.92141723632812\n","global_step=66500, episodic_return=-184.44911193847656\n","SPS: 1210\n","global_step=66812, episodic_return=-4.6873016357421875\n","global_step=66924, episodic_return=-76.40192413330078\n","global_step=67020, episodic_return=-36.463111877441406\n","global_step=67052, episodic_return=-86.26431274414062\n","SPS: 1211\n","global_step=67332, episodic_return=-18.70581817626953\n","global_step=67440, episodic_return=-125.50846862792969\n","global_step=67444, episodic_return=-9.619560241699219\n","global_step=67496, episodic_return=-94.08378601074219\n","SPS: 1213\n","global_step=67808, episodic_return=-157.22125244140625\n","global_step=67884, episodic_return=-76.95419311523438\n","SPS: 1214\n","global_step=68136, episodic_return=-24.37718963623047\n","global_step=68156, episodic_return=-73.82695007324219\n","global_step=68484, episodic_return=-192.27871704101562\n","SPS: 1215\n","global_step=68632, episodic_return=-99.91140747070312\n","global_step=68792, episodic_return=-43.172367095947266\n","global_step=68920, episodic_return=-194.21356201171875\n","global_step=68988, episodic_return=-154.4908447265625\n","SPS: 1216\n","global_step=69480, episodic_return=-75.12399291992188\n","SPS: 1216\n","global_step=69796, episodic_return=-217.88624572753906\n","global_step=70132, episodic_return=-258.437744140625\n","global_step=70140, episodic_return=-232.28366088867188\n","SPS: 1215\n","global_step=70156, episodic_return=-102.659423828125\n","SPS: 1216\n","global_step=70972, episodic_return=-167.70913696289062\n","SPS: 1215\n","global_step=71276, episodic_return=-503.1590881347656\n","global_step=71352, episodic_return=-3.3717117309570312\n","global_step=71464, episodic_return=-782.4384155273438\n","SPS: 1214\n","global_step=71988, episodic_return=-71.9724349975586\n","SPS: 1214\n","global_step=72196, episodic_return=-248.7159881591797\n","global_step=72284, episodic_return=-273.7979736328125\n","global_step=72680, episodic_return=-506.7190246582031\n","SPS: 1214\n","global_step=72760, episodic_return=-50.08631896972656\n","global_step=73028, episodic_return=-71.81999969482422\n","global_step=73152, episodic_return=-75.16876983642578\n","SPS: 1214\n","global_step=73360, episodic_return=-36.36653518676758\n","global_step=73424, episodic_return=-271.86138916015625\n","global_step=73660, episodic_return=-2.75701904296875\n","SPS: 1215\n","global_step=73896, episodic_return=10.424278259277344\n","global_step=74176, episodic_return=-115.51770782470703\n","SPS: 1215\n","global_step=74432, episodic_return=-101.92577362060547\n","global_step=74436, episodic_return=-294.39984130859375\n","global_step=74520, episodic_return=-39.75783157348633\n","SPS: 1216\n","global_step=74904, episodic_return=-72.38322448730469\n","global_step=74936, episodic_return=-26.55829620361328\n","SPS: 1216\n","global_step=75312, episodic_return=-174.9135284423828\n","global_step=75588, episodic_return=-309.3387451171875\n","SPS: 1216\n","global_step=75788, episodic_return=-24.095611572265625\n","global_step=76180, episodic_return=-93.3194580078125\n","global_step=76204, episodic_return=-79.70502471923828\n","SPS: 1216\n","global_step=76404, episodic_return=-78.98466491699219\n","global_step=76416, episodic_return=-7.786903381347656\n","global_step=76780, episodic_return=-12.024185180664062\n","SPS: 1217\n","global_step=77028, episodic_return=-161.7530975341797\n","global_step=77268, episodic_return=10.393356323242188\n","SPS: 1217\n","global_step=77608, episodic_return=-95.90462493896484\n","SPS: 1216\n","global_step=77884, episodic_return=-71.5472640991211\n","global_step=78016, episodic_return=34.11814880371094\n","global_step=78208, episodic_return=-18.36205291748047\n","SPS: 1216\n","global_step=78340, episodic_return=-101.55853271484375\n","global_step=78588, episodic_return=-174.8089599609375\n","SPS: 1214\n","global_step=78996, episodic_return=-29.3721923828125\n","global_step=79076, episodic_return=24.56018829345703\n","SPS: 1210\n","global_step=79404, episodic_return=-198.42990112304688\n","global_step=79464, episodic_return=-15.105178833007812\n","SPS: 1205\n","global_step=79944, episodic_return=-44.13246154785156\n","global_step=80112, episodic_return=-50.212162017822266\n","SPS: 1197\n","global_step=80796, episodic_return=-81.6949462890625\n","SPS: 1188\n","global_step=80940, episodic_return=-69.00732421875\n","global_step=81060, episodic_return=-34.21363830566406\n","SPS: 1180\n","global_step=81576, episodic_return=-32.35302734375\n","global_step=81740, episodic_return=-4.5513153076171875\n","SPS: 1175\n","global_step=81972, episodic_return=-85.017578125\n","global_step=82208, episodic_return=63.3432731628418\n","SPS: 1173\n","global_step=82744, episodic_return=-17.357749938964844\n","global_step=82860, episodic_return=2.9656295776367188\n","SPS: 1173\n","global_step=83112, episodic_return=-31.89208984375\n","global_step=83176, episodic_return=-60.978023529052734\n","SPS: 1173\n","global_step=83568, episodic_return=-10.362648010253906\n","global_step=83660, episodic_return=-50.00935363769531\n","SPS: 1173\n","global_step=84284, episodic_return=-5.096076965332031\n","SPS: 1173\n","global_step=84696, episodic_return=-208.68797302246094\n","global_step=84764, episodic_return=-26.9925537109375\n","global_step=84980, episodic_return=-126.20952606201172\n","SPS: 1173\n","SPS: 1173\n","global_step=85948, episodic_return=-209.4166259765625\n","SPS: 1171\n","global_step=86296, episodic_return=-0.07218170166015625\n","global_step=86340, episodic_return=-67.2570571899414\n","SPS: 1169\n","global_step=86932, episodic_return=-172.67982482910156\n","SPS: 1167\n","global_step=87156, episodic_return=-45.53240203857422\n","SPS: 1165\n","global_step=87856, episodic_return=48.3153076171875\n","SPS: 1162\n","global_step=88248, episodic_return=-117.50908660888672\n","global_step=88432, episodic_return=-288.0261535644531\n","SPS: 1159\n","global_step=88764, episodic_return=36.247562408447266\n","global_step=88976, episodic_return=6.518829345703125\n","SPS: 1158\n","SPS: 1156\n","global_step=89620, episodic_return=-74.82431030273438\n","global_step=89900, episodic_return=-11.125244140625\n","global_step=90104, episodic_return=-183.07774353027344\n","SPS: 1155\n","global_step=90592, episodic_return=-53.99363708496094\n","global_step=90600, episodic_return=-4.4582672119140625\n","global_step=90604, episodic_return=-110.17452239990234\n","SPS: 1155\n","global_step=90884, episodic_return=-41.29351806640625\n","global_step=90992, episodic_return=-11.576316833496094\n","SPS: 1156\n","global_step=91236, episodic_return=41.301513671875\n","global_step=91400, episodic_return=13.983734130859375\n","SPS: 1149\n","global_step=91720, episodic_return=6.228446960449219\n","global_step=92124, episodic_return=-15.777328491210938\n","SPS: 1139\n","global_step=92216, episodic_return=-142.95767211914062\n","global_step=92412, episodic_return=-63.55929183959961\n","SPS: 1132\n","global_step=92848, episodic_return=-2.91424560546875\n","global_step=93156, episodic_return=18.813308715820312\n","global_step=93176, episodic_return=-104.62245178222656\n","SPS: 1129\n","SPS: 1126\n","global_step=94016, episodic_return=-36.46295928955078\n","global_step=94108, episodic_return=-36.77281188964844\n","global_step=94112, episodic_return=25.439613342285156\n","SPS: 1123\n","SPS: 1123\n","global_step=94892, episodic_return=-20.08228302001953\n","SPS: 1120\n","global_step=95304, episodic_return=-73.4657211303711\n","SPS: 1118\n","global_step=95856, episodic_return=10.385627746582031\n","SPS: 1113\n","SPS: 1107\n","global_step=96848, episodic_return=92.84324645996094\n","global_step=96856, episodic_return=-51.43394470214844\n","SPS: 1104\n","SPS: 1101\n","global_step=97976, episodic_return=-60.17089080810547\n","global_step=98112, episodic_return=30.48578643798828\n","SPS: 1097\n","global_step=98800, episodic_return=1.749420166015625\n","SPS: 1096\n","SPS: 1093\n","global_step=99604, episodic_return=-219.40904235839844\n","SPS: 1089\n","global_step=99856, episodic_return=67.52700805664062\n","SPS: 1087\n","global_step=100464, episodic_return=1.7581329345703125\n","global_step=100844, episodic_return=-68.9388198852539\n","global_step=100856, episodic_return=110.04493713378906\n","SPS: 1084\n","global_step=101124, episodic_return=-0.7899932861328125\n","SPS: 1084\n","global_step=101640, episodic_return=-7.78143310546875\n","SPS: 1079\n","global_step=102048, episodic_return=-4.20941162109375\n","global_step=102112, episodic_return=59.71881103515625\n","global_step=102148, episodic_return=9.232276916503906\n","global_step=102304, episodic_return=-93.18476104736328\n","SPS: 1076\n","global_step=102816, episodic_return=-24.194442749023438\n","global_step=102880, episodic_return=14.289093017578125\n","SPS: 1075\n","global_step=103032, episodic_return=-21.997886657714844\n","SPS: 1073\n","global_step=103552, episodic_return=0.29503631591796875\n","global_step=103824, episodic_return=15.348320007324219\n","global_step=103908, episodic_return=-46.0212516784668\n","SPS: 1071\n","global_step=104396, episodic_return=11.617141723632812\n","SPS: 1069\n","global_step=104932, episodic_return=-50.464683532714844\n","SPS: 1067\n","global_step=104976, episodic_return=-85.86128997802734\n","global_step=105408, episodic_return=-24.51091766357422\n","SPS: 1067\n","SPS: 1067\n","global_step=105992, episodic_return=-0.07867431640625\n","global_step=106128, episodic_return=-267.2132873535156\n","global_step=106256, episodic_return=-75.36380004882812\n","SPS: 1067\n","global_step=106660, episodic_return=-2.5491943359375\n","SPS: 1067\n","global_step=107240, episodic_return=-224.94647216796875\n","SPS: 1067\n","global_step=107800, episodic_return=-99.95193481445312\n","global_step=107844, episodic_return=-2.8767166137695312\n","SPS: 1065\n","global_step=108472, episodic_return=-39.80891418457031\n","SPS: 1063\n","global_step=109052, episodic_return=3.5190505981445312\n","SPS: 1060\n","global_step=109176, episodic_return=-25.058258056640625\n","SPS: 1057\n","global_step=109952, episodic_return=-68.67179107666016\n","global_step=109992, episodic_return=30.63573455810547\n","SPS: 1054\n","SPS: 1053\n","global_step=110728, episodic_return=96.16471862792969\n","SPS: 1052\n","global_step=111192, episodic_return=-75.28462982177734\n","global_step=111236, episodic_return=-79.78559875488281\n","global_step=111564, episodic_return=-181.90438842773438\n","SPS: 1052\n","global_step=111924, episodic_return=0.675018310546875\n","global_step=112064, episodic_return=33.61334228515625\n","SPS: 1052\n","global_step=112380, episodic_return=15.758323669433594\n","SPS: 1053\n","global_step=112956, episodic_return=-21.505538940429688\n","global_step=113012, episodic_return=41.69255065917969\n","SPS: 1052\n","global_step=113260, episodic_return=-100.97174835205078\n","global_step=113588, episodic_return=4.991615295410156\n","SPS: 1052\n","global_step=113852, episodic_return=-52.49367141723633\n","SPS: 1051\n","global_step=114284, episodic_return=61.4979248046875\n","global_step=114488, episodic_return=38.13459777832031\n","global_step=114668, episodic_return=6.42462158203125\n","SPS: 1048\n","SPS: 1045\n","global_step=115476, episodic_return=-66.87010192871094\n","global_step=115564, episodic_return=93.9688491821289\n","SPS: 1041\n","global_step=115812, episodic_return=-37.423484802246094\n","SPS: 1039\n","global_step=116460, episodic_return=22.913902282714844\n","SPS: 1036\n","global_step=116924, episodic_return=6.4434967041015625\n","global_step=117176, episodic_return=-49.23942565917969\n","SPS: 1035\n","global_step=117496, episodic_return=-137.83050537109375\n","SPS: 1035\n","SPS: 1034\n","SPS: 1033\n","SPS: 1030\n","global_step=119328, episodic_return=-147.7581329345703\n","SPS: 1028\n","global_step=119812, episodic_return=-143.22909545898438\n","global_step=120256, episodic_return=-1.9016876220703125\n","SPS: 1026\n","global_step=120764, episodic_return=11.753913879394531\n","SPS: 1023\n","global_step=120924, episodic_return=-30.215984344482422\n","SPS: 1022\n","global_step=121496, episodic_return=82.27120208740234\n","SPS: 1021\n","global_step=122056, episodic_return=-5.976753234863281\n","SPS: 1019\n","SPS: 1018\n","global_step=123244, episodic_return=211.35549926757812\n","SPS: 1016\n","global_step=123544, episodic_return=-108.55425262451172\n","SPS: 1015\n","global_step=124256, episodic_return=75.8742446899414\n","SPS: 1013\n","SPS: 1009\n","global_step=125396, episodic_return=-65.62687683105469\n","SPS: 1004\n","global_step=125792, episodic_return=-36.294349670410156\n","SPS: 999\n","global_step=126056, episodic_return=160.8242950439453\n","SPS: 995\n","global_step=126652, episodic_return=39.98750305175781\n","SPS: 993\n","global_step=127244, episodic_return=-160.53749084472656\n","global_step=127372, episodic_return=-102.19194793701172\n","SPS: 991\n","SPS: 991\n","SPS: 989\n","global_step=128644, episodic_return=-13.854522705078125\n","SPS: 987\n","SPS: 985\n","SPS: 982\n","global_step=130056, episodic_return=-22.987701416015625\n","global_step=130364, episodic_return=233.27899169921875\n","SPS: 979\n","SPS: 977\n","global_step=131372, episodic_return=60.28599548339844\n","global_step=131504, episodic_return=-90.03793334960938\n","SPS: 975\n","global_step=131828, episodic_return=-90.93595886230469\n","SPS: 976\n","SPS: 976\n","SPS: 974\n","SPS: 971\n","global_step=133828, episodic_return=-166.5634307861328\n","SPS: 965\n","global_step=134524, episodic_return=134.39620971679688\n","SPS: 959\n","global_step=134696, episodic_return=84.41375732421875\n","SPS: 957\n","SPS: 954\n","global_step=135828, episodic_return=-76.65690612792969\n","SPS: 952\n","SPS: 949\n","global_step=137068, episodic_return=-13.193214416503906\n","SPS: 944\n","global_step=137460, episodic_return=147.6285400390625\n","SPS: 941\n","global_step=137828, episodic_return=-124.72354888916016\n","SPS: 941\n","global_step=138696, episodic_return=-30.183626174926758\n","SPS: 940\n","global_step=139072, episodic_return=210.546142578125\n","SPS: 940\n","global_step=139508, episodic_return=-126.6711196899414\n","SPS: 939\n","SPS: 938\n","SPS: 934\n","SPS: 929\n","SPS: 921\n","global_step=141828, episodic_return=-95.79115295410156\n","SPS: 915\n","global_step=142696, episodic_return=-64.82923126220703\n","SPS: 912\n","global_step=143072, episodic_return=-92.32220458984375\n","SPS: 911\n","global_step=143508, episodic_return=-25.619476318359375\n","SPS: 911\n","SPS: 910\n","SPS: 909\n","SPS: 907\n","global_step=145828, episodic_return=-99.0042495727539\n","SPS: 903\n","SPS: 900\n","global_step=146696, episodic_return=-66.38349914550781\n","SPS: 896\n","global_step=146988, episodic_return=-108.3162841796875\n","global_step=147072, episodic_return=-71.22937774658203\n","SPS: 896\n","SPS: 895\n","SPS: 893\n","SPS: 888\n","global_step=149488, episodic_return=-87.36701202392578\n","SPS: 881\n","global_step=149828, episodic_return=-7.355409145355225\n","SPS: 878\n","SPS: 876\n","global_step=150696, episodic_return=-7.7761454582214355\n","global_step=150988, episodic_return=-39.455322265625\n","SPS: 874\n","SPS: 874\n","SPS: 873\n","SPS: 870\n","SPS: 867\n","global_step=153488, episodic_return=-73.21778869628906\n","SPS: 864\n","global_step=153828, episodic_return=-85.34393310546875\n","SPS: 862\n","SPS: 861\n","global_step=154696, episodic_return=-54.99822235107422\n","global_step=154988, episodic_return=-68.12361145019531\n","SPS: 860\n","SPS: 859\n","SPS: 856\n","global_step=156440, episodic_return=175.72708129882812\n","SPS: 853\n","SPS: 849\n","SPS: 846\n","global_step=157828, episodic_return=0.046593666076660156\n","SPS: 843\n","global_step=158696, episodic_return=-12.98495864868164\n","SPS: 841\n","global_step=158988, episodic_return=-17.361202239990234\n","SPS: 841\n","SPS: 840\n","SPS: 839\n","global_step=160440, episodic_return=-88.7092056274414\n","SPS: 838\n","SPS: 837\n","SPS: 835\n","global_step=161828, episodic_return=-116.69373321533203\n","SPS: 833\n","global_step=162696, episodic_return=-63.30030822753906\n","SPS: 830\n","global_step=162988, episodic_return=-78.04633331298828\n","SPS: 828\n","SPS: 826\n","SPS: 823\n","global_step=164440, episodic_return=-59.6772346496582\n","SPS: 822\n","SPS: 821\n","global_step=165828, episodic_return=-52.97793197631836\n","SPS: 819\n","SPS: 818\n","global_step=166696, episodic_return=18.831228256225586\n","SPS: 817\n","global_step=166988, episodic_return=-101.74049377441406\n","SPS: 817\n","SPS: 817\n","global_step=168440, episodic_return=-32.212646484375\n","SPS: 816\n","SPS: 815\n","SPS: 815\n","global_step=169828, episodic_return=-107.84801483154297\n","SPS: 814\n","global_step=170008, episodic_return=-98.27885437011719\n","SPS: 813\n","global_step=170696, episodic_return=-36.6900520324707\n","global_step=170988, episodic_return=-76.49345397949219\n","SPS: 812\n","SPS: 812\n","SPS: 810\n","SPS: 807\n","SPS: 806\n","SPS: 804\n","global_step=173828, episodic_return=-70.78319549560547\n","global_step=174008, episodic_return=-92.08614349365234\n","SPS: 802\n","SPS: 801\n","global_step=174696, episodic_return=-79.55259704589844\n","global_step=174988, episodic_return=-26.82445526123047\n","SPS: 801\n","SPS: 801\n","SPS: 800\n","SPS: 797\n","SPS: 794\n","SPS: 789\n","global_step=177828, episodic_return=-20.04400634765625\n","global_step=178008, episodic_return=-78.95258331298828\n","SPS: 785\n","SPS: 782\n","global_step=178696, episodic_return=-58.158447265625\n","global_step=178988, episodic_return=-56.375274658203125\n","SPS: 782\n","SPS: 782\n","SPS: 782\n","SPS: 781\n","SPS: 779\n","SPS: 777\n","global_step=181828, episodic_return=-107.9139175415039\n","global_step=182008, episodic_return=-9.105420112609863\n","SPS: 776\n","global_step=182696, episodic_return=-59.32559585571289\n","SPS: 775\n","global_step=182988, episodic_return=-47.54954528808594\n","SPS: 775\n","SPS: 775\n","SPS: 774\n","SPS: 772\n","SPS: 768\n","global_step=185828, episodic_return=-45.21220397949219\n","SPS: 765\n","global_step=186008, episodic_return=-60.914119720458984\n","SPS: 763\n","global_step=186696, episodic_return=-33.80133819580078\n","SPS: 762\n","global_step=186988, episodic_return=-79.1720962524414\n","SPS: 762\n","SPS: 762\n","SPS: 761\n","SPS: 760\n","SPS: 758\n","global_step=189828, episodic_return=-101.55036926269531\n","SPS: 756\n","global_step=190008, episodic_return=-81.18109893798828\n","SPS: 755\n","global_step=190696, episodic_return=-40.910709381103516\n","SPS: 755\n","global_step=190988, episodic_return=-59.18318176269531\n","SPS: 754\n","SPS: 753\n","SPS: 751\n","SPS: 750\n","SPS: 748\n","global_step=193828, episodic_return=2.262575626373291\n","global_step=194008, episodic_return=-92.31143951416016\n","SPS: 746\n","SPS: 746\n","global_step=194696, episodic_return=-79.70164489746094\n","global_step=194988, episodic_return=3.092238426208496\n","SPS: 746\n","SPS: 746\n","SPS: 746\n","SPS: 745\n","SPS: 744\n","SPS: 743\n","global_step=197828, episodic_return=-52.9940185546875\n","global_step=198008, episodic_return=-83.41365814208984\n","SPS: 742\n","SPS: 739\n","global_step=198696, episodic_return=-53.745296478271484\n","global_step=198988, episodic_return=-25.27007484436035\n","SPS: 739\n","SPS: 738\n","SPS: 737\n","SPS: 736\n","SPS: 734\n","SPS: 732\n","global_step=201828, episodic_return=-73.98365783691406\n","global_step=202008, episodic_return=-47.99579620361328\n","SPS: 731\n","global_step=202696, episodic_return=-61.721920013427734\n","SPS: 731\n","global_step=202988, episodic_return=-98.18318939208984\n","SPS: 731\n","SPS: 731\n","SPS: 731\n","SPS: 730\n","SPS: 729\n","SPS: 726\n","global_step=205828, episodic_return=-69.31878662109375\n","global_step=206008, episodic_return=-52.498985290527344\n","SPS: 725\n","global_step=206696, episodic_return=-50.59599304199219\n","SPS: 725\n","global_step=206988, episodic_return=-45.73100662231445\n","SPS: 725\n","SPS: 725\n","SPS: 724\n","SPS: 723\n","SPS: 721\n","global_step=209828, episodic_return=-56.086639404296875\n","SPS: 719\n","global_step=210008, episodic_return=-50.6373405456543\n","SPS: 719\n","global_step=210696, episodic_return=-33.166011810302734\n","SPS: 719\n","global_step=210988, episodic_return=-63.98408508300781\n","SPS: 719\n","SPS: 719\n","SPS: 718\n","SPS: 715\n","SPS: 713\n","global_step=213828, episodic_return=-19.51030731201172\n","global_step=214008, episodic_return=-74.62889862060547\n","SPS: 711\n","SPS: 711\n","global_step=214696, episodic_return=14.42896842956543\n","global_step=214988, episodic_return=-51.80752944946289\n","SPS: 710\n","SPS: 711\n","SPS: 710\n","SPS: 710\n","SPS: 708\n","SPS: 707\n","global_step=217828, episodic_return=-51.44932556152344\n","global_step=218008, episodic_return=-84.2391357421875\n","SPS: 705\n","SPS: 703\n","global_step=218696, episodic_return=-17.848093032836914\n","global_step=218988, episodic_return=-40.78781509399414\n","SPS: 702\n","SPS: 702\n","SPS: 702\n","SPS: 702\n","SPS: 701\n","SPS: 700\n","global_step=221828, episodic_return=-38.03960037231445\n","global_step=222008, episodic_return=-28.54631805419922\n","SPS: 700\n","global_step=222696, episodic_return=-94.26759338378906\n","SPS: 700\n","global_step=222988, episodic_return=-58.87796401977539\n","SPS: 700\n","SPS: 701\n","SPS: 701\n","SPS: 700\n","SPS: 700\n","global_step=225308, episodic_return=-178.46377563476562\n","SPS: 699\n","global_step=226008, episodic_return=-80.84549713134766\n","SPS: 697\n","global_step=226696, episodic_return=-75.53186798095703\n","SPS: 695\n","global_step=226988, episodic_return=-48.012001037597656\n","SPS: 695\n","SPS: 695\n","SPS: 695\n","SPS: 694\n","global_step=229308, episodic_return=-52.56758499145508\n","SPS: 693\n","SPS: 692\n","global_step=230008, episodic_return=-53.885799407958984\n","SPS: 691\n","global_step=230696, episodic_return=-89.3158187866211\n","SPS: 690\n","global_step=230988, episodic_return=-28.187902450561523\n","SPS: 690\n","SPS: 690\n","SPS: 690\n","SPS: 689\n","global_step=233308, episodic_return=-36.71116638183594\n","SPS: 687\n","SPS: 687\n","global_step=234008, episodic_return=-81.08067321777344\n","SPS: 686\n","global_step=234696, episodic_return=-42.91973876953125\n","global_step=234988, episodic_return=-63.64116668701172\n","SPS: 686\n","SPS: 687\n","SPS: 687\n","SPS: 687\n","SPS: 686\n","global_step=237308, episodic_return=-67.67610931396484\n","SPS: 685\n","global_step=238008, episodic_return=-86.38631439208984\n","SPS: 685\n","SPS: 685\n","global_step=238696, episodic_return=-42.50331115722656\n","global_step=238988, episodic_return=-51.915306091308594\n","SPS: 685\n","SPS: 685\n","SPS: 685\n","SPS: 684\n","SPS: 682\n","global_step=241308, episodic_return=-94.86578369140625\n","SPS: 681\n","global_step=242008, episodic_return=-81.19096374511719\n","SPS: 680\n","SPS: 679\n","global_step=242696, episodic_return=-45.48945236206055\n","global_step=242988, episodic_return=-49.17597961425781\n","SPS: 679\n","SPS: 679\n","SPS: 679\n","SPS: 679\n","SPS: 679\n","global_step=245308, episodic_return=-85.32119750976562\n","SPS: 678\n","global_step=246008, episodic_return=-47.16096496582031\n","SPS: 678\n","global_step=246696, episodic_return=-48.48072814941406\n","SPS: 677\n","global_step=246988, episodic_return=-41.60227584838867\n","SPS: 677\n","SPS: 676\n","SPS: 675\n","SPS: 674\n","global_step=249308, episodic_return=-50.535465240478516\n","SPS: 673\n","SPS: 672\n","global_step=250008, episodic_return=-73.33917999267578\n","SPS: 672\n","global_step=250696, episodic_return=-50.79914474487305\n","SPS: 671\n","global_step=250988, episodic_return=-22.388967514038086\n","SPS: 672\n","SPS: 672\n","SPS: 672\n","SPS: 672\n","global_step=253308, episodic_return=-30.906126022338867\n","SPS: 671\n","SPS: 669\n","global_step=254008, episodic_return=13.586328506469727\n","SPS: 668\n","global_step=254696, episodic_return=-15.121539115905762\n","SPS: 667\n","global_step=254988, episodic_return=-27.23537826538086\n","SPS: 667\n","SPS: 667\n","SPS: 667\n","SPS: 666\n","global_step=257308, episodic_return=-50.31496047973633\n","SPS: 665\n","global_step=257636, episodic_return=118.80240631103516\n","SPS: 665\n","global_step=258400, episodic_return=144.42550659179688\n","SPS: 665\n","global_step=258696, episodic_return=2.704333782196045\n","SPS: 665\n","SPS: 665\n","SPS: 664\n","SPS: 663\n","SPS: 661\n","global_step=261308, episodic_return=24.063222885131836\n","global_step=261576, episodic_return=140.91734313964844\n","SPS: 660\n","global_step=261636, episodic_return=26.17713737487793\n","global_step=262116, episodic_return=-189.44882202148438\n","SPS: 660\n","SPS: 661\n","SPS: 661\n","SPS: 660\n","SPS: 660\n","SPS: 659\n","global_step=264812, episodic_return=129.55116271972656\n","global_step=264868, episodic_return=53.70089340209961\n","SPS: 659\n","global_step=265236, episodic_return=-155.87478637695312\n","SPS: 659\n","global_step=266116, episodic_return=44.59168243408203\n","SPS: 658\n","SPS: 658\n","SPS: 657\n","SPS: 656\n","global_step=267852, episodic_return=-115.3072280883789\n","global_step=267964, episodic_return=-143.99530029296875\n","SPS: 656\n","global_step=268568, episodic_return=60.78354263305664\n","SPS: 656\n","SPS: 656\n","SPS: 656\n","global_step=270116, episodic_return=19.904342651367188\n","SPS: 656\n","SPS: 656\n","global_step=271204, episodic_return=96.61902618408203\n","SPS: 655\n","global_step=271512, episodic_return=164.99423217773438\n","global_step=271740, episodic_return=142.10443115234375\n","SPS: 655\n","SPS: 655\n","SPS: 655\n","SPS: 654\n","SPS: 653\n","global_step=274116, episodic_return=59.76372528076172\n","global_step=274288, episodic_return=97.40626525878906\n","SPS: 652\n","global_step=274852, episodic_return=150.8202667236328\n","SPS: 652\n","global_step=275184, episodic_return=66.41487121582031\n","SPS: 652\n","global_step=275680, episodic_return=-87.83855438232422\n","SPS: 652\n","SPS: 652\n","SPS: 652\n","global_step=277380, episodic_return=117.71614074707031\n","SPS: 652\n","SPS: 652\n","SPS: 652\n","global_step=278852, episodic_return=29.372343063354492\n","global_step=278872, episodic_return=74.23300170898438\n","SPS: 651\n","SPS: 651\n","global_step=279680, episodic_return=99.25287628173828\n","SPS: 652\n","global_step=280524, episodic_return=-211.30386352539062\n","SPS: 652\n","SPS: 652\n","SPS: 652\n","global_step=281800, episodic_return=128.86102294921875\n","SPS: 651\n","SPS: 650\n","global_step=282852, episodic_return=13.88388729095459\n","SPS: 649\n","global_step=283592, episodic_return=79.05155181884766\n","SPS: 648\n","SPS: 648\n","global_step=284524, episodic_return=67.9868392944336\n","SPS: 648\n","SPS: 647\n","SPS: 647\n","global_step=285800, episodic_return=18.601966857910156\n","global_step=285924, episodic_return=-52.38911437988281\n","SPS: 647\n","SPS: 647\n","SPS: 647\n","global_step=287592, episodic_return=82.68944549560547\n","SPS: 647\n","global_step=288072, episodic_return=59.0105094909668\n","SPS: 647\n","SPS: 647\n","global_step=289248, episodic_return=41.74748229980469\n","SPS: 646\n","SPS: 646\n","global_step=289800, episodic_return=-83.90352630615234\n","SPS: 646\n","global_step=290320, episodic_return=156.33035278320312\n","SPS: 646\n","SPS: 646\n","global_step=291724, episodic_return=-118.60679626464844\n","SPS: 645\n","global_step=292072, episodic_return=88.86775970458984\n","SPS: 645\n","SPS: 645\n","SPS: 645\n","global_step=293588, episodic_return=39.8731803894043\n","SPS: 645\n","global_step=294320, episodic_return=90.83525085449219\n","SPS: 645\n","SPS: 645\n","global_step=295416, episodic_return=-176.855224609375\n","SPS: 644\n","SPS: 644\n","global_step=296072, episodic_return=75.64177703857422\n","SPS: 644\n","SPS: 643\n","SPS: 642\n","global_step=297588, episodic_return=35.76118087768555\n","SPS: 642\n","global_step=298320, episodic_return=-6.4564337730407715\n","SPS: 642\n","global_step=298912, episodic_return=130.53713989257812\n","SPS: 642\n","global_step=299416, episodic_return=80.8301010131836\n","SPS: 642\n","SPS: 642\n","SPS: 642\n","SPS: 642\n","SPS: 642\n","global_step=301588, episodic_return=8.800460815429688\n","global_step=301608, episodic_return=-105.67951202392578\n","SPS: 642\n","global_step=302320, episodic_return=38.04493713378906\n","SPS: 642\n","global_step=303068, episodic_return=82.61432647705078\n","SPS: 641\n","SPS: 642\n","SPS: 641\n","SPS: 641\n","SPS: 640\n","global_step=305216, episodic_return=85.22041320800781\n","global_step=305608, episodic_return=-26.123062133789062\n","SPS: 640\n","SPS: 640\n","global_step=306320, episodic_return=81.71560668945312\n","SPS: 640\n","global_step=307068, episodic_return=56.45188522338867\n","SPS: 640\n","SPS: 640\n","SPS: 640\n","SPS: 640\n","global_step=309216, episodic_return=43.61992645263672\n","SPS: 639\n","global_step=309608, episodic_return=-14.077062606811523\n","SPS: 639\n","SPS: 639\n","global_step=310320, episodic_return=-30.200008392333984\n","global_step=310544, episodic_return=-125.76783752441406\n","SPS: 639\n","SPS: 639\n","SPS: 639\n","SPS: 637\n","SPS: 636\n","global_step=313176, episodic_return=81.84974670410156\n","global_step=313216, episodic_return=41.029945373535156\n","SPS: 635\n","global_step=313600, episodic_return=-137.72116088867188\n","global_step=313740, episodic_return=86.58924102783203\n","SPS: 636\n","SPS: 636\n","SPS: 636\n","SPS: 636\n","SPS: 635\n","SPS: 634\n","SPS: 633\n","global_step=317176, episodic_return=76.96363830566406\n","global_step=317216, episodic_return=67.67256927490234\n","SPS: 632\n","global_step=317600, episodic_return=75.2724380493164\n","global_step=317740, episodic_return=53.631473541259766\n","SPS: 632\n","SPS: 632\n","SPS: 631\n","SPS: 631\n","global_step=319600, episodic_return=-39.00826644897461\n","SPS: 631\n","global_step=320044, episodic_return=111.47083282470703\n","SPS: 631\n","SPS: 631\n","global_step=321216, episodic_return=53.739952087402344\n","SPS: 631\n","global_step=321600, episodic_return=73.80113220214844\n","SPS: 631\n","SPS: 631\n","global_step=323044, episodic_return=-29.88238525390625\n","SPS: 631\n","SPS: 631\n","global_step=323600, episodic_return=114.87091827392578\n","global_step=324044, episodic_return=83.22026062011719\n","SPS: 631\n","global_step=324132, episodic_return=139.9326934814453\n","SPS: 631\n","SPS: 631\n","SPS: 631\n","SPS: 630\n","global_step=326252, episodic_return=148.58251953125\n","global_step=326528, episodic_return=182.59844970703125\n","SPS: 630\n","SPS: 630\n","SPS: 630\n","global_step=327992, episodic_return=-63.315650939941406\n","global_step=328044, episodic_return=66.07196044921875\n","global_step=328132, episodic_return=101.91189575195312\n","SPS: 630\n","global_step=328356, episodic_return=-75.93070983886719\n","SPS: 630\n","SPS: 630\n","global_step=329448, episodic_return=-48.03921890258789\n","SPS: 630\n","SPS: 630\n","global_step=330288, episodic_return=-109.36796569824219\n","SPS: 630\n","global_step=331036, episodic_return=121.62246704101562\n","global_step=331232, episodic_return=-92.8384780883789\n","SPS: 630\n","SPS: 630\n","global_step=332044, episodic_return=61.23929214477539\n","SPS: 630\n","SPS: 630\n","global_step=333260, episodic_return=-93.56543731689453\n","SPS: 629\n","SPS: 629\n","global_step=334288, episodic_return=76.89244842529297\n","SPS: 628\n","SPS: 628\n","global_step=335232, episodic_return=106.17935943603516\n","SPS: 628\n","global_step=335624, episodic_return=-81.23004150390625\n","SPS: 628\n","global_step=336044, episodic_return=81.27354431152344\n","SPS: 628\n","SPS: 628\n","SPS: 627\n","global_step=337600, episodic_return=-88.63420104980469\n","SPS: 627\n","global_step=338288, episodic_return=75.8066635131836\n","SPS: 626\n","global_step=338628, episodic_return=-101.95138549804688\n","SPS: 626\n","global_step=339232, episodic_return=52.962303161621094\n","SPS: 626\n","global_step=339836, episodic_return=-87.70699310302734\n","SPS: 626\n","SPS: 626\n","SPS: 626\n","SPS: 625\n","global_step=342004, episodic_return=116.64498901367188\n","SPS: 625\n","global_step=342068, episodic_return=90.64178466796875\n","global_step=342288, episodic_return=6.806699275970459\n","SPS: 625\n","SPS: 625\n","SPS: 625\n","global_step=343836, episodic_return=51.47784423828125\n","SPS: 625\n","global_step=344272, episodic_return=-181.38296508789062\n","SPS: 625\n","global_step=344800, episodic_return=-105.81940460205078\n","SPS: 626\n","SPS: 626\n","global_step=345788, episodic_return=-105.70276641845703\n","SPS: 626\n","global_step=346152, episodic_return=-99.59461212158203\n","global_step=346288, episodic_return=-1.380317211151123\n","SPS: 626\n","SPS: 626\n","SPS: 626\n","SPS: 625\n","global_step=348260, episodic_return=-75.61936950683594\n","global_step=348280, episodic_return=-154.0243682861328\n","SPS: 625\n","global_step=348800, episodic_return=53.361793518066406\n","SPS: 625\n","global_step=349204, episodic_return=123.35787963867188\n","SPS: 625\n","SPS: 625\n","SPS: 625\n","global_step=350748, episodic_return=-118.16813659667969\n","SPS: 625\n","global_step=351652, episodic_return=-95.4866714477539\n","SPS: 624\n","SPS: 624\n","global_step=352280, episodic_return=42.02975845336914\n","global_step=352580, episodic_return=104.80903625488281\n","SPS: 624\n","SPS: 624\n","SPS: 624\n","SPS: 624\n","global_step=354748, episodic_return=29.484779357910156\n","global_step=354760, episodic_return=-118.59303283691406\n","SPS: 623\n","SPS: 623\n","global_step=355652, episodic_return=44.35079574584961\n","SPS: 622\n","global_step=355996, episodic_return=-68.23075866699219\n","SPS: 622\n","global_step=356508, episodic_return=-88.33626556396484\n","global_step=356580, episodic_return=85.11541748046875\n","SPS: 622\n","SPS: 622\n","SPS: 622\n","global_step=358168, episodic_return=-47.34272384643555\n","SPS: 622\n","global_step=358896, episodic_return=160.4408416748047\n","SPS: 622\n","global_step=359348, episodic_return=-174.8101348876953\n","SPS: 622\n","SPS: 622\n","global_step=359996, episodic_return=44.896034240722656\n","SPS: 622\n","SPS: 622\n","SPS: 621\n","SPS: 621\n","global_step=362168, episodic_return=6.842530727386475\n","SPS: 619\n","global_step=362896, episodic_return=39.36176300048828\n","SPS: 619\n","global_step=363348, episodic_return=78.33694458007812\n","SPS: 618\n","global_step=363996, episodic_return=43.04437255859375\n","SPS: 618\n","SPS: 618\n","global_step=364964, episodic_return=137.31765747070312\n","SPS: 618\n","global_step=365476, episodic_return=162.50216674804688\n","SPS: 618\n","SPS: 618\n","global_step=366220, episodic_return=-119.35382843017578\n","SPS: 618\n","SPS: 618\n","global_step=367180, episodic_return=73.80598449707031\n","global_step=367596, episodic_return=-117.33848571777344\n","SPS: 618\n","SPS: 618\n","SPS: 617\n","global_step=368964, episodic_return=60.51881790161133\n","SPS: 617\n","SPS: 616\n","SPS: 615\n","global_step=370220, episodic_return=91.64749908447266\n","SPS: 615\n","global_step=371180, episodic_return=72.59037017822266\n","SPS: 615\n","global_step=371596, episodic_return=70.36275482177734\n","SPS: 615\n","global_step=372024, episodic_return=127.36388397216797\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","SPS: 615\n","global_step=373940, episodic_return=-134.61293029785156\n","global_step=374220, episodic_return=37.61013412475586\n","SPS: 615\n","SPS: 615\n","global_step=375180, episodic_return=57.3155403137207\n","SPS: 615\n","SPS: 615\n","global_step=376000, episodic_return=-66.82246398925781\n","global_step=376024, episodic_return=37.37675094604492\n","SPS: 615\n","SPS: 615\n","SPS: 615\n","global_step=377396, episodic_return=77.65522766113281\n","global_step=377832, episodic_return=102.26033020019531\n","SPS: 614\n","global_step=378116, episodic_return=133.44357299804688\n","SPS: 615\n","global_step=378496, episodic_return=132.24269104003906\n","SPS: 615\n","SPS: 615\n","global_step=379728, episodic_return=-145.39212036132812\n","SPS: 615\n","global_step=379940, episodic_return=-78.0555419921875\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","global_step=381832, episodic_return=32.69780731201172\n","SPS: 616\n","SPS: 615\n","global_step=382496, episodic_return=85.31217956542969\n","global_step=382588, episodic_return=121.89724731445312\n","SPS: 616\n","SPS: 616\n","global_step=383940, episodic_return=49.13406753540039\n","SPS: 616\n","global_step=384244, episodic_return=-141.78085327148438\n","SPS: 616\n","SPS: 616\n","global_step=385440, episodic_return=-73.65446472167969\n","SPS: 616\n","global_step=385904, episodic_return=119.13780212402344\n","SPS: 615\n","global_step=386496, episodic_return=58.045814514160156\n","SPS: 615\n","global_step=386732, episodic_return=-39.91065979003906\n","SPS: 615\n","SPS: 616\n","global_step=387940, episodic_return=5.39149284362793\n","SPS: 616\n","global_step=388184, episodic_return=-111.77914428710938\n","SPS: 616\n","SPS: 616\n","global_step=389272, episodic_return=97.45693969726562\n","SPS: 616\n","SPS: 616\n","global_step=390208, episodic_return=-230.25845336914062\n","global_step=390448, episodic_return=27.979324340820312\n","SPS: 617\n","SPS: 617\n","global_step=391320, episodic_return=148.21441650390625\n","SPS: 617\n","global_step=392184, episodic_return=70.88087463378906\n","SPS: 617\n","global_step=392436, episodic_return=136.05178833007812\n","SPS: 617\n","SPS: 617\n","global_step=393236, episodic_return=-74.04021453857422\n","global_step=393260, episodic_return=-60.72468566894531\n","SPS: 617\n","SPS: 617\n","global_step=394448, episodic_return=62.080379486083984\n","global_step=394468, episodic_return=-109.54263305664062\n","SPS: 617\n","SPS: 617\n","global_step=395520, episodic_return=-53.016151428222656\n","SPS: 617\n","SPS: 616\n","SPS: 616\n","global_step=397260, episodic_return=38.275726318359375\n","SPS: 616\n","global_step=397400, episodic_return=-60.27337646484375\n","SPS: 615\n","global_step=398112, episodic_return=177.34576416015625\n","SPS: 615\n","global_step=398448, episodic_return=57.06549835205078\n","SPS: 615\n","global_step=399360, episodic_return=-72.07080078125\n","SPS: 616\n","SPS: 616\n","global_step=399996, episodic_return=-79.23353576660156\n","global_step=400088, episodic_return=197.8551025390625\n","global_step=400104, episodic_return=178.2980194091797\n","SPS: 616\n","SPS: 616\n","global_step=401028, episodic_return=-80.64047241210938\n","SPS: 616\n","SPS: 616\n","global_step=402240, episodic_return=-130.39678955078125\n","SPS: 616\n","global_step=402488, episodic_return=-105.09291076660156\n","SPS: 616\n","SPS: 616\n","SPS: 615\n","global_step=404008, episodic_return=-78.91681671142578\n","global_step=404088, episodic_return=41.8753662109375\n","SPS: 615\n","SPS: 615\n","global_step=405028, episodic_return=121.56432342529297\n","SPS: 616\n","SPS: 616\n","global_step=406028, episodic_return=-56.66687774658203\n","global_step=406240, episodic_return=100.0276870727539\n","global_step=406252, episodic_return=154.27696228027344\n","SPS: 616\n","global_step=406908, episodic_return=136.61631774902344\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","global_step=410028, episodic_return=99.51751708984375\n","SPS: 616\n","global_step=410240, episodic_return=82.61605072021484\n","global_step=410252, episodic_return=55.52851104736328\n","SPS: 616\n","global_step=410908, episodic_return=87.40396881103516\n","SPS: 617\n","SPS: 617\n","global_step=411856, episodic_return=155.93722534179688\n","SPS: 617\n","global_step=412260, episodic_return=173.8140106201172\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","global_step=414240, episodic_return=82.12576293945312\n","SPS: 616\n","global_step=414836, episodic_return=199.80157470703125\n","global_step=414908, episodic_return=89.0313491821289\n","SPS: 616\n","SPS: 616\n","global_step=415856, episodic_return=82.191162109375\n","SPS: 616\n","SPS: 616\n","global_step=416980, episodic_return=140.1009521484375\n","SPS: 616\n","SPS: 616\n","global_step=418240, episodic_return=77.1783218383789\n","SPS: 616\n","SPS: 616\n","global_step=418836, episodic_return=96.50933837890625\n","SPS: 616\n","SPS: 616\n","global_step=419856, episodic_return=89.33671569824219\n","SPS: 615\n","SPS: 615\n","global_step=420980, episodic_return=101.3231430053711\n","SPS: 615\n","global_step=421504, episodic_return=158.37567138671875\n","SPS: 615\n","global_step=422240, episodic_return=67.87285614013672\n","SPS: 615\n","global_step=422696, episodic_return=-55.4570198059082\n","SPS: 615\n","SPS: 615\n","global_step=423856, episodic_return=102.70764923095703\n","SPS: 615\n","SPS: 615\n","SPS: 615\n","global_step=425136, episodic_return=-30.79053497314453\n","SPS: 615\n","global_step=425504, episodic_return=68.67485809326172\n","SPS: 614\n","global_step=426240, episodic_return=86.78688049316406\n","SPS: 614\n","global_step=426696, episodic_return=95.69703674316406\n","SPS: 614\n","global_step=427196, episodic_return=-132.07669067382812\n","SPS: 614\n","SPS: 614\n","global_step=428048, episodic_return=-100.17467498779297\n","global_step=428380, episodic_return=-63.33681869506836\n","SPS: 614\n","global_step=428664, episodic_return=124.63220977783203\n","SPS: 614\n","SPS: 614\n","global_step=429732, episodic_return=-133.15090942382812\n","SPS: 615\n","SPS: 614\n","global_step=430792, episodic_return=-164.2015380859375\n","global_step=430900, episodic_return=151.52960205078125\n","SPS: 614\n","SPS: 615\n","SPS: 615\n","global_step=432160, episodic_return=-115.0252456665039\n","global_step=432380, episodic_return=67.92626953125\n","SPS: 615\n","global_step=432888, episodic_return=-122.49446105957031\n","SPS: 615\n","SPS: 615\n","SPS: 614\n","SPS: 614\n","global_step=434792, episodic_return=123.72084045410156\n","SPS: 613\n","SPS: 613\n","global_step=436160, episodic_return=63.74751281738281\n","SPS: 612\n","global_step=436380, episodic_return=43.713035583496094\n","SPS: 613\n","global_step=436888, episodic_return=96.07475280761719\n","global_step=437036, episodic_return=-94.44688415527344\n","SPS: 613\n","SPS: 613\n","global_step=437796, episodic_return=-68.84325408935547\n","SPS: 613\n","global_step=438380, episodic_return=-76.75271606445312\n","global_step=438680, episodic_return=190.99002075195312\n","SPS: 614\n","SPS: 614\n","global_step=439372, episodic_return=127.92547607421875\n","SPS: 614\n","global_step=439980, episodic_return=-112.986083984375\n","SPS: 614\n","SPS: 614\n","global_step=440844, episodic_return=145.02606201171875\n","SPS: 614\n","SPS: 614\n","global_step=442072, episodic_return=162.07901000976562\n","global_step=442272, episodic_return=128.38377380371094\n","SPS: 615\n","global_step=442380, episodic_return=65.97559356689453\n","SPS: 615\n","SPS: 615\n","global_step=443648, episodic_return=-45.76227951049805\n","global_step=443764, episodic_return=-38.2883415222168\n","global_step=443880, episodic_return=176.99658203125\n","SPS: 615\n","SPS: 615\n","SPS: 615\n","SPS: 615\n","global_step=445564, episodic_return=-83.04417419433594\n","global_step=445692, episodic_return=-104.05438995361328\n","SPS: 615\n","global_step=446016, episodic_return=152.24395751953125\n","global_step=446380, episodic_return=86.94526672363281\n","SPS: 615\n","SPS: 615\n","SPS: 615\n","global_step=447548, episodic_return=143.53204345703125\n","SPS: 615\n","global_step=448004, episodic_return=-88.92877960205078\n","global_step=448008, episodic_return=174.99061584472656\n","global_step=448356, episodic_return=136.03790283203125\n","SPS: 616\n","SPS: 616\n","global_step=449312, episodic_return=-42.90260696411133\n","SPS: 616\n","SPS: 616\n","global_step=450488, episodic_return=-86.2051010131836\n","SPS: 616\n","global_step=450608, episodic_return=162.16102600097656\n","SPS: 616\n","global_step=451452, episodic_return=180.90805053710938\n","SPS: 616\n","global_step=452004, episodic_return=65.41802215576172\n","SPS: 616\n","SPS: 617\n","SPS: 616\n","SPS: 616\n","SPS: 615\n","global_step=454488, episodic_return=42.06867599487305\n","global_step=454608, episodic_return=116.77323913574219\n","SPS: 615\n","SPS: 615\n","global_step=455452, episodic_return=74.33847045898438\n","SPS: 615\n","global_step=456004, episodic_return=65.08389282226562\n","global_step=456112, episodic_return=-65.81436157226562\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","global_step=457532, episodic_return=-113.4768295288086\n","SPS: 616\n","global_step=457808, episodic_return=-133.9326934814453\n","SPS: 616\n","global_step=458608, episodic_return=63.307830810546875\n","SPS: 616\n","global_step=458764, episodic_return=93.43994903564453\n","SPS: 616\n","SPS: 616\n","global_step=459864, episodic_return=-152.03958129882812\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","global_step=461808, episodic_return=101.90804290771484\n","SPS: 616\n","SPS: 616\n","global_step=462560, episodic_return=125.91252899169922\n","global_step=462576, episodic_return=199.69989013671875\n","global_step=462608, episodic_return=101.84037017822266\n","SPS: 616\n","global_step=462924, episodic_return=-81.4000244140625\n","SPS: 616\n","SPS: 616\n","SPS: 616\n","global_step=464572, episodic_return=-129.82237243652344\n","SPS: 616\n","SPS: 616\n","global_step=465572, episodic_return=211.69189453125\n","global_step=465668, episodic_return=-239.2743682861328\n","SPS: 616\n","SPS: 617\n","global_step=466540, episodic_return=195.29360961914062\n","global_step=466608, episodic_return=89.97130584716797\n","SPS: 617\n","global_step=467028, episodic_return=-97.66271209716797\n","SPS: 617\n","global_step=467608, episodic_return=-68.36387634277344\n","SPS: 617\n","global_step=468392, episodic_return=-98.19404602050781\n","SPS: 617\n","SPS: 618\n","global_step=469392, episodic_return=-84.08085632324219\n","SPS: 618\n","global_step=469600, episodic_return=141.8037109375\n","global_step=469804, episodic_return=-167.28030395507812\n","SPS: 618\n","global_step=470252, episodic_return=-158.07530212402344\n","SPS: 618\n","SPS: 618\n","global_step=471280, episodic_return=-53.22300338745117\n","SPS: 618\n","global_step=471840, episodic_return=-136.26708984375\n","SPS: 618\n","SPS: 618\n","SPS: 618\n","global_step=473392, episodic_return=79.91751861572266\n","SPS: 617\n","global_step=473672, episodic_return=-235.98089599609375\n","global_step=473812, episodic_return=146.29574584960938\n","SPS: 618\n","SPS: 618\n","global_step=474796, episodic_return=-67.46919250488281\n","SPS: 618\n","global_step=475304, episodic_return=-80.66532897949219\n","SPS: 618\n","global_step=475704, episodic_return=-246.94920349121094\n","SPS: 618\n","SPS: 618\n","SPS: 618\n","global_step=477608, episodic_return=160.25729370117188\n","SPS: 618\n","SPS: 618\n","SPS: 617\n","global_step=478796, episodic_return=90.84332275390625\n","global_step=478856, episodic_return=222.68280029296875\n","global_step=479104, episodic_return=74.5677490234375\n","SPS: 618\n","global_step=479612, episodic_return=155.4444580078125\n","SPS: 618\n","global_step=480052, episodic_return=-90.41348266601562\n","global_step=480100, episodic_return=-90.17915344238281\n","SPS: 618\n","global_step=480568, episodic_return=-88.38008880615234\n","SPS: 618\n","SPS: 618\n","global_step=481388, episodic_return=-139.94937133789062\n","SPS: 618\n","SPS: 618\n","global_step=482472, episodic_return=-102.95471954345703\n","global_step=482648, episodic_return=-106.2474594116211\n","SPS: 618\n","SPS: 618\n","SPS: 618\n"]}]},{"cell_type":"markdown","metadata":{"id":"eVsVJ5AdqLE7"},"source":["## Some additional challenges üèÜ\n","The best way to learn **is to try things by your own**! Why not trying  another environment?\n"]},{"cell_type":"markdown","metadata":{"id":"nYdl758GqLXT"},"source":["See you on Unit 8, part 2 where we going to train agents to play Doom üî•\n","## Keep learning, stay awesome ü§ó"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/huggingface/deep-rl-class/blob/main/notebooks/unit8/unit8_part1.ipynb","timestamp":1678978045944}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e0adc9f92fef465ba2193fe9edca6519":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_73b5af72222b422d933dd7532cd67834","IPY_MODEL_d7bbd6b8c51b41d5ac9af290955a3196","IPY_MODEL_c16e816bd3f94eaea040ed4565981747","IPY_MODEL_e42744f31eb345dfa612e642e28489f2","IPY_MODEL_718dd093a6214972b925370af8622d7d"],"layout":"IPY_MODEL_697969006d7b47f6a875a53a04a922d3"}},"73b5af72222b422d933dd7532cd67834":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e02e330103a04c9db94beb86b7902991","placeholder":"‚Äã","style":"IPY_MODEL_5d8ddaa2ba7f45f986fd7f60cd5143a8","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"d7bbd6b8c51b41d5ac9af290955a3196":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_870f13ef760b4fb899b2760852e5f59d","placeholder":"‚Äã","style":"IPY_MODEL_b15491dd899247c6800f0d32f6141ec4","value":""}},"c16e816bd3f94eaea040ed4565981747":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_674c64d1e71144a4b7f8c538192474dd","style":"IPY_MODEL_545230d1f60548d8ba9ad6f1185a6755","value":true}},"e42744f31eb345dfa612e642e28489f2":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_6082fc5b3f7b4ec0b052d0f5826bc828","style":"IPY_MODEL_0e015cfe2afb43bfb9c4215df5e99c44","tooltip":""}},"718dd093a6214972b925370af8622d7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4da17a40638b49e19bb26249690c5bd6","placeholder":"‚Äã","style":"IPY_MODEL_0d6ab09a77824ea4bd4849fecc8b0349","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"697969006d7b47f6a875a53a04a922d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"e02e330103a04c9db94beb86b7902991":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d8ddaa2ba7f45f986fd7f60cd5143a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"870f13ef760b4fb899b2760852e5f59d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15491dd899247c6800f0d32f6141ec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"674c64d1e71144a4b7f8c538192474dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"545230d1f60548d8ba9ad6f1185a6755":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6082fc5b3f7b4ec0b052d0f5826bc828":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e015cfe2afb43bfb9c4215df5e99c44":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"4da17a40638b49e19bb26249690c5bd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d6ab09a77824ea4bd4849fecc8b0349":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}